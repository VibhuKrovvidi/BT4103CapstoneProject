{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Workflow\n",
    "\n",
    "Feature Extraction + Word embedding + Clustering + Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.2.0.json: 128kB [00:00, 1.46MB/s]\n",
      "2021-03-25 23:44:52 INFO: Downloading default packages for language: en (English)...\n",
      "2021-03-25 23:44:54 INFO: File exists: C:\\Users\\TzeMin\\stanza_resources\\en\\default.zip.\n",
      "2021-03-25 23:45:00 INFO: Finished downloading models and saved to C:\\Users\\TzeMin\\stanza_resources.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\TzeMin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\TzeMin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\TzeMin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import regex\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import stanza\n",
    "stanza.download('en') # download English model\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(txt, nlp):\n",
    "    \n",
    "    sentList = nltk.sent_tokenize(txt)\n",
    "    retlist = [];\n",
    "    \n",
    "    for line in sentList:\n",
    "        txt_list = nltk.word_tokenize(line)\n",
    "        taggedList = nltk.pos_tag(txt_list)\n",
    "        newwordList = []\n",
    "        flag = 0\n",
    "        \n",
    "        for i in range(0,len(taggedList)-1):\n",
    "            if(taggedList[i][1]==\"NN\" and taggedList[i+1][1]==\"NN\"):\n",
    "                newwordList.append(taggedList[i][0]+taggedList[i+1][0])\n",
    "                flag=1\n",
    "            else:\n",
    "                if(flag==1):\n",
    "                    flag=0\n",
    "                    continue\n",
    "                newwordList.append(taggedList[i][0])\n",
    "                if(i==len(taggedList)-2):\n",
    "                    newwordList.append(taggedList[i+1][0])\n",
    "        finaltxt = ' '.join(word for word in newwordList)\n",
    "    \n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        new_txt_list = nltk.word_tokenize(finaltxt)\n",
    "        wordsList = [w for w in new_txt_list if not w in stop_words]\n",
    "        taggedList = nltk.pos_tag(wordsList)\n",
    "        \n",
    "        doc = nlp(finaltxt)\n",
    "        dep_node = []\n",
    "        try:\n",
    "            for dep_edge in doc.sentences[0].dependencies:\n",
    "                dep_node.append([dep_edge[2].text, dep_edge[0].id, dep_edge[1]])\n",
    "            for i in range(0, len(dep_node)):\n",
    "                if (int(dep_node[i][1]) != 0):\n",
    "                    dep_node[i][1] = newwordList[(int(dep_node[i][1]) - 1)]\n",
    "        except:\n",
    "            pass;\n",
    "                \n",
    "        featureList = []\n",
    "        categories = []\n",
    "        for i in taggedList:\n",
    "            if(i[1]=='JJ' or i[1]=='NN' or i[1]=='JJR' or i[1]=='NNS' or i[1]=='RB'):\n",
    "                featureList.append(list(i))\n",
    "                categories.append(i[0])        \n",
    "        \n",
    "        fcluster = []\n",
    "        for i in featureList:\n",
    "            filist = []\n",
    "            for j in dep_node:\n",
    "                if((j[0]==i[0] or j[1]==i[0]) and (j[2] in [\n",
    "                    # Different types of words that are identified as potential features\n",
    "                    \"nsubj\",\n",
    "                    #\"acl:relcl\",\n",
    "                    \"obj\",\n",
    "                    \"dobj\",\n",
    "                    #\"agent\",\n",
    "                    #\"advmod\",\n",
    "                    #\"amod\",\n",
    "                    #\"neg\",\n",
    "                    #\"prep_of\",\n",
    "                    #\"acomp\",\n",
    "                    #\"xcomp\",\n",
    "                    #\"compound\"\n",
    "                ])):\n",
    "                    if(j[0]==i[0]):\n",
    "                        filist.append(j[1])\n",
    "                    else:\n",
    "                        filist.append(j[0])\n",
    "            fcluster.append([i[0], filist])\n",
    "        print(fcluster) \n",
    "        \n",
    "        # Remove all features with no sentiment word:\n",
    "        retlist.append(fcluster)\n",
    "    return retlist;\n",
    "\n",
    "def do_extraction(df, nlp, feat_count, feat_sent, content_str = \"Content\"):\n",
    "    idx = 0;\n",
    "    # Replace \"\" with nan's for removal\n",
    "    df[content_str].replace('', np.nan, inplace=True)\n",
    "    df.dropna(subset=[content_str], inplace=True)\n",
    "    review_list = df[content_str].to_list()     \n",
    "    print(\" Processing : \" , df.shape[0], \"rows of data\")\n",
    "    \n",
    "    for review in tqdm(review_list):\n",
    "        print(\"Review Number : \", idx);\n",
    "        \n",
    "        # Some data pre-processing\n",
    "        review = review.lower()\n",
    "        \n",
    "        # Merge hyphenated words\n",
    "        separate = review.split('-')\n",
    "        review = ''.join(separate)\n",
    "        \n",
    "        # Remove non-alphabets\n",
    "        review = re.sub(r'[^a-z\\s\\t]', '', review)\n",
    "        \n",
    "        idx += 1;\n",
    "        if idx >= df.shape[0]:\n",
    "            break;\n",
    "        try:\n",
    "            output = feature_extraction(review, nlp);\n",
    "        except:\n",
    "            pass;\n",
    "        for sent in output:\n",
    "            for pair in sent:\n",
    "                print(pair)\n",
    "                if pair[0] in feat_sent:\n",
    "                    if pair[1] is not None:\n",
    "                        flist = feat_sent[pair[0]]\n",
    "                        if isinstance(pair[1], list):\n",
    "                            for i in pair[1]:\n",
    "                                flist.append(i)\n",
    "                        else:\n",
    "                            flist.append(pair[1])\n",
    "                        feat_sent[pair[0]] = flist;\n",
    "                else:\n",
    "                    if pair[1] is not None:\n",
    "                        flist = pair[1]\n",
    "                    else:\n",
    "                        flist = list()\n",
    "                    feat_sent[pair[0]] = flist;\n",
    "                \n",
    "                if pair[0] in feat_count:\n",
    "                    feat_count[pair[0]] = feat_count[pair[0]] + 1;\n",
    "                else:\n",
    "                    feat_count[pair[0]] = 1\n",
    "    \n",
    "    return feat_count, feat_sent;\n",
    "\n",
    "def get_sentiment(feat_count, feat_sent, nlp):\n",
    "\n",
    "    sentiment_score = dict()\n",
    "\n",
    "    # Delete features with no descriptors\n",
    "    cob = feat_sent.copy()\n",
    "    for feat in cob.keys():\n",
    "        if cob[feat] == []:\n",
    "            del feat_sent[feat]\n",
    "        else:\n",
    "            feat_sent[feat] = ' ,'.join(feat_sent[feat])\n",
    "\n",
    "    # Run pre-built sentiment score and take avg of all descriptors\n",
    "    for f in tqdm(feat_sent.keys()):\n",
    "        print(\"Calculating Sentiment for: \", f);\n",
    "        ssum = 0;\n",
    "        for g in feat_sent[f]:\n",
    "            try:\n",
    "                doc = nlp(g);\n",
    "                for i in doc.sentences:\n",
    "                        ssum += i.sentiment;\n",
    "            except:\n",
    "                pass;\n",
    "        sentiment_score[f] = ssum / len(b[f])\n",
    "\n",
    "    adf = pd.DataFrame.from_dict(feat_count, orient='index', columns=['Freq'])\n",
    "    adf.sort_values(by=\"Freq\", ascending=False, inplace = True)\n",
    "\n",
    "    avg_sent = pd.DataFrame.from_dict(sentiment_score, orient='index', columns=[\"Avg_sent\"])\n",
    "    desc_words = pd.DataFrame.from_dict(feat_sent, orient=\"index\", columns=[\"Descriptors\"])\n",
    "    \n",
    "    avg_sent = avg_sent.merge(desc_words, left_index=True, right_index=True)\n",
    "    final_sent = avg_sent.merge(adf, left_index=True, right_index=True)\n",
    "    final_sent.sort_values(by=\"Freq\", ascending=False, inplace=True)\n",
    "    return final_sent;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-25 23:45:00 INFO: Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | combined  |\n",
      "| pos       | combined  |\n",
      "| lemma     | combined  |\n",
      "| depparse  | combined  |\n",
      "| sentiment | sstplus   |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2021-03-25 23:45:00 INFO: Use device: cpu\n",
      "2021-03-25 23:45:00 INFO: Loading: tokenize\n",
      "2021-03-25 23:45:00 INFO: Loading: pos\n",
      "2021-03-25 23:45:01 INFO: Loading: lemma\n",
      "2021-03-25 23:45:01 INFO: Loading: depparse\n",
      "2021-03-25 23:45:01 INFO: Loading: sentiment\n",
      "2021-03-25 23:45:02 INFO: Loading: ner\n",
      "2021-03-25 23:45:03 INFO: Done loading processors!\n",
      "  0%|                                                                                           | 0/52 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing :  52 rows of data\n",
      "Review Number :  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█▌                                                                                 | 1/52 [00:00<00:29,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['professional', []], ['people', ['recommended']], ['patient', []], ['kind', ['recommended']], ['respectful', []], ['smooth', []], ['medical', []], ['checkup', []]]\n",
      "['professional', []]\n",
      "['people', ['recommended']]\n",
      "['patient', []]\n",
      "['kind', ['recommended']]\n",
      "['respectful', []]\n",
      "['smooth', []]\n",
      "['medical', []]\n",
      "['checkup', []]\n",
      "Review Number :  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|███▏                                                                               | 2/52 [00:01<00:26,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['reviews', ['suggest']], ['people', ['suggest']], ['adequately', []], ['anywhere', []], ['else', []], ['sg', []], ['place', ['clean']], ['really', []], ['clean', ['place']], ['efficient', []]]\n",
      "['reviews', ['suggest']]\n",
      "['people', ['suggest']]\n",
      "['adequately', []]\n",
      "['anywhere', []]\n",
      "['else', []]\n",
      "['sg', []]\n",
      "['place', ['clean']]\n",
      "['really', []]\n",
      "['clean', ['place']]\n",
      "['efficient', []]\n",
      "Review Number :  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|████▊                                                                              | 3/52 [00:01<00:27,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['place', ['experience']], ['overall', []], ['fine', []], ['good', []], ['experience', ['place']], ['tip', []], ['u', ['have']], ['medical', []], ['checkupdont', []], ['late', []], ['else', []], ['u', ['have']], ['back', []], ['day', []], ['complete', ['rest']], ['rest', ['complete']]]\n",
      "['place', ['experience']]\n",
      "['overall', []]\n",
      "['fine', []]\n",
      "['good', []]\n",
      "['experience', ['place']]\n",
      "['tip', []]\n",
      "['u', ['have']]\n",
      "['medical', []]\n",
      "['checkupdont', []]\n",
      "['late', []]\n",
      "['else', []]\n",
      "['u', ['have']]\n",
      "['back', []]\n",
      "['day', []]\n",
      "['complete', ['rest']]\n",
      "['rest', ['complete']]\n",
      "Review Number :  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██████▍                                                                            | 4/52 [00:02<00:31,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['nscheckup', []], ['checkuptoday', []], ['gateentrance', []], ['entrancesecurity', []], ['checkcounter', []], ['stickerpass', ['take']], ['walk', []], ['gatedont', []], ['mei', ['stood']], ['thinking', []], ['scan', ['i', 'the']]]\n",
      "['nscheckup', []]\n",
      "['checkuptoday', []]\n",
      "['gateentrance', []]\n",
      "['entrancesecurity', []]\n",
      "['checkcounter', []]\n",
      "['stickerpass', ['take']]\n",
      "['walk', []]\n",
      "['gatedont', []]\n",
      "['mei', ['stood']]\n",
      "['thinking', []]\n",
      "['scan', ['i', 'the']]\n",
      "Review Number :  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|███████▉                                                                           | 5/52 [00:03<00:35,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['dontbother', ['end']], ['youll', []], ['end', ['dontbother']], ['hours', []], ['realise', ['that', 'youre']], ['youre', ['realise']], ['last', []], ['person', ['care']], ['line', []], ['doctors', []], ['really', []], ['fair', ['which']], ['dont', []], ['really', []], ['choice', ['have']], ['place', ['waste']], ['complete', []], ['waste', ['place']], ['space', []], ['time', []]]\n",
      "['dontbother', ['end']]\n",
      "['youll', []]\n",
      "['end', ['dontbother']]\n",
      "['hours', []]\n",
      "['realise', ['that', 'youre']]\n",
      "['youre', ['realise']]\n",
      "['last', []]\n",
      "['person', ['care']]\n",
      "['line', []]\n",
      "['doctors', []]\n",
      "['really', []]\n",
      "['fair', ['which']]\n",
      "['dont', []]\n",
      "['really', []]\n",
      "['choice', ['have']]\n",
      "['place', ['waste']]\n",
      "['complete', []]\n",
      "['waste', ['place']]\n",
      "['space', []]\n",
      "['time', []]\n",
      "Review Number :  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█████████▌                                                                         | 6/52 [00:03<00:25,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['nsf', []], ['reviews', []], ['lol', []]]\n",
      "['nsf', []]\n",
      "['reviews', []]\n",
      "['lol', []]\n",
      "Review Number :  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|███████████▏                                                                       | 7/52 [00:03<00:21,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['extremely', []], ['long', []], ['time', ['takes']], ['due', []], ['overall', []], ['complete', []], ['waste', ['waiting']], ['time', ['takes']]]\n",
      "['extremely', []]\n",
      "['long', []]\n",
      "['time', ['takes']]\n",
      "['due', []]\n",
      "['overall', []]\n",
      "['complete', []]\n",
      "['waste', ['waiting']]\n",
      "['time', ['takes']]\n",
      "Review Number :  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|████████████▊                                                                      | 8/52 [00:04<00:23,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['staff', ['professional']], ['professional', ['staff']], ['idk', []], ['bad', []], ['reviews', ['what']], ['personal', []], ['experienceeveryone', []], ['helpful', ['is']], ['initiative', ['take']], ['help', ['me']]]\n",
      "['staff', ['professional']]\n",
      "['professional', ['staff']]\n",
      "['idk', []]\n",
      "['bad', []]\n",
      "['reviews', ['what']]\n",
      "['personal', []]\n",
      "['experienceeveryone', []]\n",
      "['helpful', ['is']]\n",
      "['initiative', ['take']]\n",
      "['help', ['me']]\n",
      "Review Number :  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|██████████████▎                                                                    | 9/52 [00:05<00:29,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['unfriendly', []], ['staff', ['keep']], ['guards', ['doing']], ['job', ['doing']], ['staff', ['keep']], ['stuff', ['do']], ['suppose', ['which', 'they']], ['absolutely', []], ['atrocious', []], ['woman', ['is']], ['keeps', ['who']], ['tone', ['changing']], ['talks', ['she']], ['people', ['threatens']], ['people', ['threatens']], ['always', []], ['mask', ['removes']], ['talk', []], ['people', ['threatens']], ['expressions', ['show']]]\n",
      "['unfriendly', []]\n",
      "['staff', ['keep']]\n",
      "['guards', ['doing']]\n",
      "['job', ['doing']]\n",
      "['staff', ['keep']]\n",
      "['stuff', ['do']]\n",
      "['suppose', ['which', 'they']]\n",
      "['absolutely', []]\n",
      "['atrocious', []]\n",
      "['woman', ['is']]\n",
      "['keeps', ['who']]\n",
      "['tone', ['changing']]\n",
      "['talks', ['she']]\n",
      "['people', ['threatens']]\n",
      "['people', ['threatens']]\n",
      "['always', []]\n",
      "['mask', ['removes']]\n",
      "['talk', []]\n",
      "['people', ['threatens']]\n",
      "['expressions', ['show']]\n",
      "Review Number :  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|███████████████▊                                                                  | 10/52 [00:05<00:24,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['staff', ['rude']], ['medical', []], ['screening', []], ['station', []], ['weight', []], ['extremely', []], ['rude', ['staff']], ['unfriendly', []]]\n",
      "['staff', ['rude']]\n",
      "['medical', []]\n",
      "['screening', []]\n",
      "['station', []]\n",
      "['weight', []]\n",
      "['extremely', []]\n",
      "['rude', ['staff']]\n",
      "['unfriendly', []]\n",
      "Review Number :  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|█████████████████▎                                                                | 11/52 [00:06<00:21,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['staff', ['impatient']], ['serious', []], ['impatient', ['staff']], ['undesirably', []], ['long', []], ['times', ['recommend']], ['cmpb', ['recommend']], ['friend', []]]\n",
      "['staff', ['impatient']]\n",
      "['serious', []]\n",
      "['impatient', ['staff']]\n",
      "['undesirably', []]\n",
      "['long', []]\n",
      "['times', ['recommend']]\n",
      "['cmpb', ['recommend']]\n",
      "['friend', []]\n",
      "Review Number :  11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██████████████████▉                                                               | 12/52 [00:07<00:23,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['sent', ['son']], ['son', ['sent', 'got']], ['preenlistment', []], ['enlistmentcheckup', []], ['morning', []], ['guard', ['give']], ['entrancecouldnt', []], ['clear', []], ['instructions', ['give']], ['son', ['sent', 'got']], ['alight', []], ['couldnt', []], ['drive', ['we']], ['hello', []], ['please', []], ['train', ['army']], ['army', ['train']]]\n",
      "['sent', ['son']]\n",
      "['son', ['sent', 'got']]\n",
      "['preenlistment', []]\n",
      "['enlistmentcheckup', []]\n",
      "['morning', []]\n",
      "['guard', ['give']]\n",
      "['entrancecouldnt', []]\n",
      "['clear', []]\n",
      "['instructions', ['give']]\n",
      "['son', ['sent', 'got']]\n",
      "['alight', []]\n",
      "['couldnt', []]\n",
      "['drive', ['we']]\n",
      "['hello', []]\n",
      "['please', []]\n",
      "['train', ['army']]\n",
      "['army', ['train']]\n",
      "Review Number :  12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|████████████████████▌                                                             | 13/52 [00:07<00:21,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['inconvenient', []], ['locations', []], ['ever', []], ['terrible', []], ['directions', ['seen']], ['staff', ['expect']], ['whole', []], ['process', ['expect']], ['take', ['hours']], ['hours', ['take']]]\n",
      "['inconvenient', []]\n",
      "['locations', []]\n",
      "['ever', []]\n",
      "['terrible', []]\n",
      "['directions', ['seen']]\n",
      "['staff', ['expect']]\n",
      "['whole', []]\n",
      "['process', ['expect']]\n",
      "['take', ['hours']]\n",
      "['hours', ['take']]\n",
      "Review Number :  13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██████████████████████                                                            | 14/52 [00:08<00:23,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ok', ['staff']], ['lah', []], ['review', []], ['visitjanuary', []], ['maybe', []], ['sikit', []], ['date', []], ['nsf', []], ['staff', ['ok']], ['ok', ['staff']], ['typical', []], ['bochap', []], ['happy', []], ['bird', []], ['tio', ['vocationmo']], ['switch', []], ['vocationmo', ['tio']], ['hand', []], ['si', []], ['pehbuay', []], ['buaysong', []], ['probably', ['this']]]\n",
      "['ok', ['staff']]\n",
      "['lah', []]\n",
      "['review', []]\n",
      "['visitjanuary', []]\n",
      "['maybe', []]\n",
      "['sikit', []]\n",
      "['date', []]\n",
      "['nsf', []]\n",
      "['staff', ['ok']]\n",
      "['ok', ['staff']]\n",
      "['typical', []]\n",
      "['bochap', []]\n",
      "['happy', []]\n",
      "['bird', []]\n",
      "['tio', ['vocationmo']]\n",
      "['switch', []]\n",
      "['vocationmo', ['tio']]\n",
      "['hand', []]\n",
      "['si', []]\n",
      "['pehbuay', []]\n",
      "['buaysong', []]\n",
      "['probably', ['this']]\n",
      "Review Number :  14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|███████████████████████▋                                                          | 15/52 [00:08<00:19,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['tbh', []], ['bad', ['its']], ['place', []], ['visit', []], ['contrary', []], ['others', ['saying']]]\n",
      "['tbh', []]\n",
      "['bad', ['its']]\n",
      "['place', []]\n",
      "['visit', []]\n",
      "['contrary', []]\n",
      "['others', ['saying']]\n",
      "Review Number :  15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|█████████████████████████▏                                                        | 16/52 [00:09<00:21,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['please', []], ['sure', []], ['medical', []], ['conditions', ['declare']], ['severe', []], ['minor', []], ['medical', []], ['officer', []], ['checkup', []], ['fare', ['you']], ['well', []], ['medical', []], ['specialistletter', ['get']]]\n",
      "['please', []]\n",
      "['sure', []]\n",
      "['medical', []]\n",
      "['conditions', ['declare']]\n",
      "['severe', []]\n",
      "['minor', []]\n",
      "['medical', []]\n",
      "['officer', []]\n",
      "['checkup', []]\n",
      "['fare', ['you']]\n",
      "['well', []]\n",
      "['medical', []]\n",
      "['specialistletter', ['get']]\n",
      "Review Number :  16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|██████████████████████████▊                                                       | 17/52 [00:09<00:18,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['guards', ['ask']], ['rude', []], ['ask', ['guards', 'question']], ['question', ['ask']], ['ignore', ['they']], ['rest', ['nice']], ['staff', []], ['nice', ['rest']], ['friendly', []]]\n",
      "['guards', ['ask']]\n",
      "['rude', []]\n",
      "['ask', ['guards', 'question']]\n",
      "['question', ['ask']]\n",
      "['ignore', ['they']]\n",
      "['rest', ['nice']]\n",
      "['staff', []]\n",
      "['nice', ['rest']]\n",
      "['friendly', []]\n",
      "Review Number :  17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|████████████████████████████▍                                                     | 18/52 [00:10<00:15,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['overall', []], ['great', []], ['experience', []], ['medic', ['professional']], ['professional', ['medic']], ['blooddraw', []]]\n",
      "['overall', []]\n",
      "['great', []]\n",
      "['experience', []]\n",
      "['medic', ['professional']]\n",
      "['professional', ['medic']]\n",
      "['blooddraw', []]\n",
      "Review Number :  18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███████████████████████████████▌                                                  | 20/52 [00:10<00:10,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['kind', []], ['people', []], ['cmpd', []], ['medical', []], ['check', []], ['constantly', []], ['smile', []], ['patience', []]]\n",
      "['kind', []]\n",
      "['people', []]\n",
      "['cmpd', []]\n",
      "['medical', []]\n",
      "['check', []]\n",
      "['constantly', []]\n",
      "['smile', []]\n",
      "['patience', []]\n",
      "Review Number :  19\n",
      "[['dont', []], ['bully', ['me']]]\n",
      "['dont', []]\n",
      "['bully', ['me']]\n",
      "Review Number :  20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████                                                 | 21/52 [00:10<00:08,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['meh', []], ['staff', ['nice']], ['pretty', []], ['nice', ['staff']]]\n",
      "['meh', []]\n",
      "['staff', ['nice']]\n",
      "['pretty', []]\n",
      "['nice', ['staff']]\n",
      "Review Number :  21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|██████████████████████████████████▋                                               | 22/52 [00:10<00:08,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['lousy', []], ['service', []], ['dk', []], ['help', ['ask']], ['people', ['ask']], ['question', ['ask']], ['also', []], ['dont', []], ['ask', ['help', 'people', 'question', 'taiji']], ['taiji', ['ask']]]\n",
      "['lousy', []]\n",
      "['service', []]\n",
      "['dk', []]\n",
      "['help', ['ask']]\n",
      "['people', ['ask']]\n",
      "['question', ['ask']]\n",
      "['also', []]\n",
      "['dont', []]\n",
      "['ask', ['help', 'people', 'question', 'taiji']]\n",
      "['taiji', ['ask']]\n",
      "Review Number :  22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|█████████████████████████████████████▊                                            | 24/52 [00:11<00:09,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['tuesday', []], ['negative', []], ['reviews', []], ['share', ['i', 'opinion']], ['quick', []], ['personal', []], ['opinion', ['share']], ['perhaps', []], ['varies', ['it']], ['person', []], ['person', []], ['trip', ['great']], ['cmpb', []], ['ultimately', []], ['great', ['trip']], ['definitely', []], ['memorable', []], ['experience', []], ['medical', []]]\n",
      "['tuesday', []]\n",
      "['negative', []]\n",
      "['reviews', []]\n",
      "['share', ['i', 'opinion']]\n",
      "['quick', []]\n",
      "['personal', []]\n",
      "['opinion', ['share']]\n",
      "['perhaps', []]\n",
      "['varies', ['it']]\n",
      "['person', []]\n",
      "['person', []]\n",
      "['trip', ['great']]\n",
      "['cmpb', []]\n",
      "['ultimately', []]\n",
      "['great', ['trip']]\n",
      "['definitely', []]\n",
      "['memorable', []]\n",
      "['experience', []]\n",
      "['medical', []]\n",
      "Review Number :  23\n",
      "[['medical', []], ['check', ['place']], ['place', ['check']], ['saf', []]]\n",
      "['medical', []]\n",
      "['check', ['place']]\n",
      "['place', ['check']]\n",
      "['saf', []]\n",
      "Review Number :  24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|███████████████████████████████████████▍                                          | 25/52 [00:12<00:07,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['others', []], ['dirt', []]]\n",
      "['others', []]\n",
      "['dirt', []]\n",
      "Review Number :  25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████                                         | 26/52 [00:12<00:08,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['preenlistment', []], ['sessions', ['screening']], ['chargeinconvenient', []], ['inconvenientlocation', ['answer']]]\n",
      "['preenlistment', []]\n",
      "['sessions', ['screening']]\n",
      "['chargeinconvenient', []]\n",
      "['inconvenientlocation', ['answer']]\n",
      "Review Number :  26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|██████████████████████████████████████████▌                                       | 27/52 [00:12<00:07,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['cookhouse', []], ['nsf', ['need']], ['meagre', []], ['pay', []]]\n",
      "['cookhouse', []]\n",
      "['nsf', ['need']]\n",
      "['meagre', []]\n",
      "['pay', []]\n",
      "Review Number :  27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|████████████████████████████████████████████▏                                     | 28/52 [00:13<00:09,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['officerattitude', ['good']], ['good', ['officerattitude']], ['patience', ['understand']], ['servicei', []], ['dont', []], ['use', ['he', 'tone']], ['unfriendly', []], ['tone', ['use']], ['repeat', []], ['language', []]]\n",
      "['officerattitude', ['good']]\n",
      "['good', ['officerattitude']]\n",
      "['patience', ['understand']]\n",
      "['servicei', []]\n",
      "['dont', []]\n",
      "['use', ['he', 'tone']]\n",
      "['unfriendly', []]\n",
      "['tone', ['use']]\n",
      "['repeat', []]\n",
      "['language', []]\n",
      "Review Number :  28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|███████████████████████████████████████████████▎                                  | 30/52 [00:14<00:07,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['idk', []], ['many', []], ['people', ['give']], ['negative', []], ['reviews', ['give']], ['medical', []], ['check', []], ['staff', ['friendly']], ['friendly', ['staff']], ['nsf', ['cool']], ['cool', ['nsf']], ['overall', []], ['good', []], ['experience', ['had']]]\n",
      "['idk', []]\n",
      "['many', []]\n",
      "['people', ['give']]\n",
      "['negative', []]\n",
      "['reviews', ['give']]\n",
      "['medical', []]\n",
      "['check', []]\n",
      "['staff', ['friendly']]\n",
      "['friendly', ['staff']]\n",
      "['nsf', ['cool']]\n",
      "['cool', ['nsf']]\n",
      "['overall', []]\n",
      "['good', []]\n",
      "['experience', ['had']]\n",
      "Review Number :  29\n",
      "[['gold', []], ['star', []], ['public', []], ['service', []]]\n",
      "['gold', []]\n",
      "['star', []]\n",
      "['public', []]\n",
      "['service', []]\n",
      "Review Number :  30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████████████████████████████████████████████████▍                               | 32/52 [00:14<00:06,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['hrs', []], ['form', []], ['meeting', []], ['even', []], ['really', []], ['bored', []], ['cold', []], ['air', []], ['wifi', []]]\n",
      "['hrs', []]\n",
      "['form', []]\n",
      "['meeting', []]\n",
      "['even', []]\n",
      "['really', []]\n",
      "['bored', []]\n",
      "['cold', []]\n",
      "['air', []]\n",
      "['wifi', []]\n",
      "Review Number :  31\n",
      "[['accessible', []]]\n",
      "['accessible', []]\n",
      "Review Number :  32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|█████████████████████████████████████████████████████▌                            | 34/52 [00:15<00:04,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['extremely', []], ['poor', []], ['rude', []], ['customerservice', []]]\n",
      "['extremely', []]\n",
      "['poor', []]\n",
      "['rude', []]\n",
      "['customerservice', []]\n",
      "Review Number :  33\n",
      "[['worst', []], ['day', []], ['life', []]]\n",
      "['worst', []]\n",
      "['day', []]\n",
      "['life', []]\n",
      "Review Number :  34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|███████████████████████████████████████████████████████▏                          | 35/52 [00:15<00:04,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['wooo', []], ['real', []], ['edgy', []], ['ziyuan', ['writer']], ['novel', []], ['writer', ['ziyuan', 'you']]]\n",
      "['wooo', []]\n",
      "['real', []]\n",
      "['edgy', []]\n",
      "['ziyuan', ['writer']]\n",
      "['novel', []]\n",
      "['writer', ['ziyuan', 'you']]\n",
      "Review Number :  35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|██████████████████████████████████████████████████████████▎                       | 37/52 [00:15<00:03,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['highly', []], ['inaccessible', []], ['hard', []], ['get', []], ['mrt', []], ['stations', []]]\n",
      "['highly', []]\n",
      "['inaccessible', []]\n",
      "['hard', []]\n",
      "['get', []]\n",
      "['mrt', []]\n",
      "['stations', []]\n",
      "Review Number :  36\n",
      "[['bane', []], ['existence', []]]\n",
      "['bane', []]\n",
      "['existence', []]\n",
      "Review Number :  37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████████████████████████████████████████████████████████▉                      | 38/52 [00:16<00:04,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['cookhouse', []], ['book', []], ['everyday', []], ['troublesome', []], ['thing', ['discussing']], ['whats', ['discussing']], ['sidenotecanteen', []], ['canteenb', ['bad']], ['bad', ['canteenb']], ['real', []], ['bad', ['canteenb']]]\n",
      "['cookhouse', []]\n",
      "['book', []]\n",
      "['everyday', []]\n",
      "['troublesome', []]\n",
      "['thing', ['discussing']]\n",
      "['whats', ['discussing']]\n",
      "['sidenotecanteen', []]\n",
      "['canteenb', ['bad']]\n",
      "['bad', ['canteenb']]\n",
      "['real', []]\n",
      "['bad', ['canteenb']]\n",
      "Review Number :  38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|█████████████████████████████████████████████████████████████▌                    | 39/52 [00:16<00:03,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['people', ['go']], ['even', []], ['placemiddle', []], ['nowhere', []]]\n",
      "['people', ['go']]\n",
      "['even', []]\n",
      "['placemiddle', []]\n",
      "['nowhere', []]\n",
      "Review Number :  39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|████████████████████████████████████████████████████████████████▋                 | 41/52 [00:17<00:02,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['officertalk', []], ['money', ['own']], ['hard', []], ['middle', []], ['village', []], ['something', []]]\n",
      "['officertalk', []]\n",
      "['money', ['own']]\n",
      "['hard', []]\n",
      "['middle', []]\n",
      "['village', []]\n",
      "['something', []]\n",
      "Review Number :  40\n",
      "[['rude', []], ['staff', []]]\n",
      "['rude', []]\n",
      "['staff', []]\n",
      "Review Number :  41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|███████████████████████████████████████████████████████████████████▊              | 43/52 [00:17<00:02,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['inaccessible', []], ['need', []], ['h', []], ['time', ['travel']], ['waste', ['more']], ['time', ['travel']]]\n",
      "['inaccessible', []]\n",
      "['need', []]\n",
      "['h', []]\n",
      "['time', ['travel']]\n",
      "['waste', ['more']]\n",
      "['time', ['travel']]\n",
      "Review Number :  42\n",
      "[['far', []], ['away', []], ['middle', []], ['nowhere', []]]\n",
      "['far', []]\n",
      "['away', []]\n",
      "['middle', []]\n",
      "['nowhere', []]\n",
      "Review Number :  43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|██████████████████████████████████████████████████████████████████████▉           | 45/52 [00:17<00:01,  4.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['bad', []], ['security', []], ['troopers', []], ['bad', []], ['attitude', ['have']], ['towards', []], ['public', []]]\n",
      "['bad', []]\n",
      "['security', []]\n",
      "['troopers', []]\n",
      "['bad', []]\n",
      "['attitude', ['have']]\n",
      "['towards', []]\n",
      "['public', []]\n",
      "Review Number :  44\n",
      "[['middle', []], ['nowhere', []]]\n",
      "['middle', []]\n",
      "['nowhere', []]\n",
      "Review Number :  45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████████████████████████████████████████        | 47/52 [00:18<00:01,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['place', []], ['well', []], ['people', ['kept']], ['unbelievably', []]]\n",
      "['place', []]\n",
      "['well', []]\n",
      "['people', ['kept']]\n",
      "['unbelievably', []]\n",
      "Review Number :  46\n",
      "[['bad', []], ['service', []]]\n",
      "['bad', []]\n",
      "['service', []]\n",
      "Review Number :  47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████████████████████████████████████████████████████████████████████████▎    | 49/52 [00:18<00:00,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['interestingly', []], ['enough', []], ['negative', []], ['reviews', []]]\n",
      "['interestingly', []]\n",
      "['enough', []]\n",
      "['negative', []]\n",
      "['reviews', []]\n",
      "Review Number :  48\n",
      "[['bad', []], ['service', []]]\n",
      "['bad', []]\n",
      "['service', []]\n",
      "Review Number :  49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|████████████████████████████████████████████████████████████████████████████████▍ | 51/52 [00:19<00:00,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['sheat', []], ['dirty', []], ['pigs', []], ['step', []], ['minefields', []]]\n",
      "['sheat', []]\n",
      "['dirty', []]\n",
      "['pigs', []]\n",
      "['step', []]\n",
      "['minefields', []]\n",
      "Review Number :  50\n",
      "[['gncpresent', []]]\n",
      "['gncpresent', []]\n",
      "Review Number :  51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rdr = pd.read_csv('../../output/scraped-ns/cmpb.csv')\n",
    "\n",
    "nlp = stanza.Pipeline('en')\n",
    "a = dict()\n",
    "b = dict()\n",
    "a, b = do_extraction(rdr, nlp, a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/89 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  professional\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▉                                                                                  | 1/89 [00:00<01:17,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  people\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█▊                                                                                 | 2/89 [00:05<04:35,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  kind\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▊                                                                                | 3/89 [00:06<02:58,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  reviews\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|███▋                                                                               | 4/89 [00:07<02:27,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  place\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|████▋                                                                              | 5/89 [00:09<02:33,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  clean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|█████▌                                                                             | 6/89 [00:09<01:50,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  good\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██████▌                                                                            | 7/89 [00:11<01:41,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  experience\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|███████▍                                                                           | 8/89 [00:11<01:24,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  u\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████▍                                                                          | 9/89 [00:12<01:14,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█████████▏                                                                        | 10/89 [00:12<00:57,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  rest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|██████████▏                                                                       | 11/89 [00:13<01:01,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  stickerpass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|███████████                                                                       | 12/89 [00:13<00:49,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  mei\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|███████████▉                                                                      | 13/89 [00:14<00:42,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  scan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|████████████▉                                                                     | 14/89 [00:14<00:37,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  dontbother\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█████████████▊                                                                    | 15/89 [00:14<00:30,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  end\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|██████████████▋                                                                   | 16/89 [00:15<00:35,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  hours\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|███████████████▋                                                                  | 17/89 [00:15<00:31,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  realise\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                 | 18/89 [00:16<00:36,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  youre\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|█████████████████▌                                                                | 19/89 [00:16<00:35,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██████████████████▍                                                               | 20/89 [00:17<00:30,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  fair\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|███████████████████▎                                                              | 21/89 [00:17<00:28,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  choice\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|████████████████████▎                                                             | 22/89 [00:17<00:25,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  waste\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|█████████████████████▏                                                            | 23/89 [00:19<00:43,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██████████████████████                                                            | 24/89 [00:20<01:03,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  nsf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|███████████████████████                                                           | 25/89 [00:21<00:56,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  staff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|███████████████████████▉                                                          | 26/89 [00:25<01:59,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  bad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|█████████████████████████▊                                                        | 28/89 [00:27<01:19,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  helpful\n",
      "Calculating Sentiment for:  initiative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|██████████████████████████▋                                                       | 29/89 [00:27<00:59,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  help\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███████████████████████████▋                                                      | 30/89 [00:28<00:48,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  guards\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|████████████████████████████▌                                                     | 31/89 [00:28<00:44,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  job\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|██████████████████████████████▍                                                   | 33/89 [00:29<00:27,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  stuff\n",
      "Calculating Sentiment for:  suppose\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|████████████████████████████████▏                                                 | 35/89 [00:30<00:23,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  woman\n",
      "Calculating Sentiment for:  keeps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                | 36/89 [00:30<00:19,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  tone\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|██████████████████████████████████                                                | 37/89 [00:31<00:27,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  talks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|███████████████████████████████████                                               | 38/89 [00:31<00:22,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|███████████████████████████████████▉                                              | 39/89 [00:32<00:22,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  expressions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████████████████████████████████████▊                                             | 40/89 [00:32<00:19,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  rude\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|█████████████████████████████████████▊                                            | 41/89 [00:32<00:18,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  impatient\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|██████████████████████████████████████▋                                           | 42/89 [00:33<00:17,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  times\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|███████████████████████████████████████▌                                          | 43/89 [00:33<00:21,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  cmpb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████████████████████████████████████████▍                                        | 45/89 [00:34<00:18,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  sent\n",
      "Calculating Sentiment for:  son\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|██████████████████████████████████████████▍                                       | 46/89 [00:35<00:28,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  guard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|███████████████████████████████████████████▎                                      | 47/89 [00:36<00:23,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  instructions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████████████████████████████████████████████▏                                    | 49/89 [00:36<00:15,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  drive\n",
      "Calculating Sentiment for:  train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|██████████████████████████████████████████████                                    | 50/89 [00:36<00:13,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  army\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|██████████████████████████████████████████████▉                                   | 51/89 [00:37<00:13,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  directions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|███████████████████████████████████████████████▉                                  | 52/89 [00:37<00:12,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|████████████████████████████████████████████████▊                                 | 53/89 [00:37<00:13,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  take\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|█████████████████████████████████████████████████▊                                | 54/89 [00:38<00:12,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████████████████████████████████████████████████▋                               | 55/89 [00:39<00:17,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  tio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|███████████████████████████████████████████████████▌                              | 56/89 [00:39<00:18,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  vocationmo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|████████████████████████████████████████████████████▌                             | 57/89 [00:39<00:14,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  probably\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|█████████████████████████████████████████████████████▍                            | 58/89 [00:40<00:12,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  others\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████████████████████████████████████████████████████▎                           | 59/89 [00:40<00:12,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  conditions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|███████████████████████████████████████████████████████▎                          | 60/89 [00:41<00:12,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  fare\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|████████████████████████████████████████████████████████▏                         | 61/89 [00:41<00:10,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  specialistletter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|█████████████████████████████████████████████████████████                         | 62/89 [00:41<00:08,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  ask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|██████████████████████████████████████████████████████████                        | 63/89 [00:44<00:29,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  question\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|██████████████████████████████████████████████████████████▉                       | 64/89 [00:45<00:23,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  ignore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████████████████████████████████████████████████████████▉                      | 65/89 [00:45<00:17,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  nice\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|████████████████████████████████████████████████████████████▊                     | 66/89 [00:46<00:17,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  friendly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|█████████████████████████████████████████████████████████████▋                    | 67/89 [00:46<00:14,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  great\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|██████████████████████████████████████████████████████████████▋                   | 68/89 [00:46<00:11,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  medic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████████████████████████████████████████████████████████████▌                  | 69/89 [00:47<00:12,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  check\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|████████████████████████████████████████████████████████████████▍                 | 70/89 [00:48<00:10,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  patience\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|██████████████████████████████████████████████████████████████████▎               | 72/89 [00:49<00:07,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  bully\n",
      "Calculating Sentiment for:  taiji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|███████████████████████████████████████████████████████████████████▎              | 73/89 [00:49<00:06,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  share\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████████████████████████████████████████████████████████████████▏             | 74/89 [00:49<00:06,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  opinion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|██████████████████████████████████████████████████████████████████████            | 76/89 [00:50<00:04,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  varies\n",
      "Calculating Sentiment for:  trip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|██████████████████████████████████████████████████████████████████████▉           | 77/89 [00:50<00:04,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  sessions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|███████████████████████████████████████████████████████████████████████▊          | 78/89 [00:51<00:04,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  inconvenientlocation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████████████████████████████████████████████████████████████████████▊         | 79/89 [00:51<00:04,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  officerattitude\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████████████████████████████████████████████████████████████████████▋        | 80/89 [00:52<00:03,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  use\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|██████████████████████████████████████████████████████████████████████████▋       | 81/89 [00:52<00:03,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  cool\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|███████████████████████████████████████████████████████████████████████████▌      | 82/89 [00:52<00:02,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  ziyuan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|████████████████████████████████████████████████████████████████████████████▍     | 83/89 [00:53<00:02,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  writer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████████████████████████████████████████████████████████████████████████▍    | 84/89 [00:54<00:02,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  thing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|██████████████████████████████████████████████████████████████████████████████▎   | 85/89 [00:54<00:02,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  whats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|███████████████████████████████████████████████████████████████████████████████▏  | 86/89 [00:55<00:01,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  canteenb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|████████████████████████████████████████████████████████████████████████████████▏ | 87/89 [00:55<00:00,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  money\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████████████████████████████████████████████████████████████████████████████ | 88/89 [00:55<00:00,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sentiment for:  attitude\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 89/89 [00:56<00:00,  1.58it/s]\n"
     ]
    }
   ],
   "source": [
    "fin = get_sentiment(a, b, nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg_sent</th>\n",
       "      <th>Descriptors</th>\n",
       "      <th>Freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>staff</th>\n",
       "      <td>0.884058</td>\n",
       "      <td>professional ,keep ,keep ,rude ,impatient ,exp...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>people</th>\n",
       "      <td>0.891892</td>\n",
       "      <td>recommended ,suggest ,threatens ,threatens ,th...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bad</th>\n",
       "      <td>0.913043</td>\n",
       "      <td>its ,canteenb ,canteenb</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews</th>\n",
       "      <td>0.894737</td>\n",
       "      <td>suggest ,what ,give</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>place</th>\n",
       "      <td>0.903226</td>\n",
       "      <td>clean ,experience ,waste ,check</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>army</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>army</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>directions</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>seen</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>process</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>expect</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attitude</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>have</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Avg_sent                                        Descriptors  Freq\n",
       "staff       0.884058  professional ,keep ,keep ,rude ,impatient ,exp...    11\n",
       "people      0.891892  recommended ,suggest ,threatens ,threatens ,th...    10\n",
       "bad         0.913043                            its ,canteenb ,canteenb     8\n",
       "reviews     0.894737                                suggest ,what ,give     6\n",
       "place       0.903226                    clean ,experience ,waste ,check     6\n",
       "...              ...                                                ...   ...\n",
       "train       1.000000                                               army     1\n",
       "army        1.000000                                              train     1\n",
       "directions  1.000000                                               seen     1\n",
       "process     1.000000                                             expect     1\n",
       "attitude    1.000000                                               have     1\n",
       "\n",
       "[89 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfidf_features(df, content_str = \"Content\", min_ = 2, max_ = 0.5, ngramrange = (1,2)):\n",
    "    review_list = df[content_str].to_list()\n",
    "    tfidf = TfidfVectorizer(min_df = min_, max_df = max_, ngram_range = ngramrange);\n",
    "    features = tfidf.fit_transform(review_list);\n",
    "    q = pd.DataFrame(features.todense(), columns=tfidf.get_feature_names())\n",
    "    return list(q.columns)\n",
    "\n",
    "def refine_features(originaldf, sentimentdf):\n",
    "    tfidf_output = get_tfidf_features(originaldf)\n",
    "    sentimentdf = sentimentdf.reset_index()\n",
    "    ft_extract = set(sentimentdf['index']);\n",
    "    tfidf_extract = set(tfidf_output)\n",
    "    \n",
    "    intersecting_features = ft_extract.intersection(tfidf_extract)\n",
    "    \n",
    "    return_df = sentimentdf\n",
    "    return_df = return_df.loc[return_df['index'].isin(list(intersecting_features))]\n",
    "    print(\"Number of extracted features:\")\n",
    "    print(\"Initial = \", len(ft_extract), \" TFIDF = \", len(intersecting_features), \" Final after intersection = \", return_df.shape[0])\n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of extracted features:\n",
      "Initial =  89  TFIDF =  31  Final after intersection =  31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Avg_sent</th>\n",
       "      <th>Descriptors</th>\n",
       "      <th>Freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>staff</td>\n",
       "      <td>0.884058</td>\n",
       "      <td>professional ,keep ,keep ,rude ,impatient ,exp...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>people</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>recommended ,suggest ,threatens ,threatens ,th...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bad</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>its ,canteenb ,canteenb</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>reviews</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>suggest ,what ,give</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>place</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>clean ,experience ,waste ,check</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>time</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>takes ,takes ,travel ,travel</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rude</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>staff</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>experience</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>place ,had</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nsf</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>need ,cool</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>professional</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>staff ,medic</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>person</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>care</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>waste</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>place ,waiting ,more</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>complete</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>rest</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>good</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>officerattitude</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>check</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>place</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>help</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>me ,ask</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cmpb</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>recommend</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>guards</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>doing ,ask</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>great</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>trip</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>friendly</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>staff</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>tone</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>changing ,use</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>nice</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>rest ,staff</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>patience</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>understand</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>question</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>ask ,ask</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>hours</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>take</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ask</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>guards ,question ,help ,people ,question ,taiji</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>others</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>saying</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>rest</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>complete ,nice</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>kind</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>recommended</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>take</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>hours</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>attitude</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>have</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           index  Avg_sent                                        Descriptors  \\\n",
       "0          staff  0.884058  professional ,keep ,keep ,rude ,impatient ,exp...   \n",
       "1         people  0.891892  recommended ,suggest ,threatens ,threatens ,th...   \n",
       "2            bad  0.913043                            its ,canteenb ,canteenb   \n",
       "3        reviews  0.894737                                suggest ,what ,give   \n",
       "4          place  0.903226                    clean ,experience ,waste ,check   \n",
       "5           time  0.892857                       takes ,takes ,travel ,travel   \n",
       "6           rude  1.000000                                              staff   \n",
       "7     experience  0.900000                                         place ,had   \n",
       "8            nsf  0.900000                                         need ,cool   \n",
       "9   professional  0.916667                                       staff ,medic   \n",
       "10        person  1.000000                                               care   \n",
       "11         waste  0.900000                               place ,waiting ,more   \n",
       "12      complete  1.000000                                               rest   \n",
       "13          good  1.000000                                    officerattitude   \n",
       "14         check  1.000000                                              place   \n",
       "15          help  0.857143                                            me ,ask   \n",
       "16          cmpb  1.000000                                          recommend   \n",
       "17        guards  0.900000                                         doing ,ask   \n",
       "19         great  1.000000                                               trip   \n",
       "20      friendly  1.000000                                              staff   \n",
       "21          tone  0.923077                                      changing ,use   \n",
       "22          nice  0.909091                                        rest ,staff   \n",
       "23      patience  1.000000                                         understand   \n",
       "24      question  0.875000                                           ask ,ask   \n",
       "25         hours  1.000000                                               take   \n",
       "26           ask  0.893617    guards ,question ,help ,people ,question ,taiji   \n",
       "27        others  1.000000                                             saying   \n",
       "28          rest  0.928571                                     complete ,nice   \n",
       "31          kind  1.000000                                        recommended   \n",
       "58          take  1.000000                                              hours   \n",
       "88      attitude  1.000000                                               have   \n",
       "\n",
       "    Freq  \n",
       "0     11  \n",
       "1     10  \n",
       "2      8  \n",
       "3      6  \n",
       "4      6  \n",
       "5      5  \n",
       "6      4  \n",
       "7      4  \n",
       "8      4  \n",
       "9      3  \n",
       "10     3  \n",
       "11     3  \n",
       "12     3  \n",
       "13     3  \n",
       "14     3  \n",
       "15     2  \n",
       "16     2  \n",
       "17     2  \n",
       "19     2  \n",
       "20     2  \n",
       "21     2  \n",
       "22     2  \n",
       "23     2  \n",
       "24     2  \n",
       "25     2  \n",
       "26     2  \n",
       "27     2  \n",
       "28     2  \n",
       "31     2  \n",
       "58     1  \n",
       "88     1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refined = refine_features(rdr, fin)\n",
    "refined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Word Embedding + Clustering\n",
    "\n",
    "Do some cleaning first. From the set of refined features, we removed stop words, then stemmed them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from sklearn.cluster import KMeans\n",
    "from tqdm import tqdm\n",
    "from gensim.models import Word2Vec \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import normalize\n",
    "import spacy\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      staff\n",
       "1     people\n",
       "2        bad\n",
       "3    reviews\n",
       "4      place\n",
       "Name: index, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncleaned_words = refined['index']\n",
    "uncleaned_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words removed were:  {'take', 'others'}\n",
      "From 31 to 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>staff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>reviews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>place</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nsf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>professional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>waste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>complete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>check</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cmpb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>guards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>friendly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>tone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>nice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>patience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>hours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>rest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>kind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>attitude</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word\n",
       "0          staff\n",
       "1         people\n",
       "2            bad\n",
       "3        reviews\n",
       "4          place\n",
       "5           time\n",
       "6           rude\n",
       "7     experience\n",
       "8            nsf\n",
       "9   professional\n",
       "10        person\n",
       "11         waste\n",
       "12      complete\n",
       "13          good\n",
       "14         check\n",
       "15          help\n",
       "16          cmpb\n",
       "17        guards\n",
       "18         great\n",
       "19      friendly\n",
       "20          tone\n",
       "21          nice\n",
       "22      patience\n",
       "23      question\n",
       "24         hours\n",
       "25           ask\n",
       "26          rest\n",
       "27          kind\n",
       "28      attitude"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\") # to run on command prompt: python -m spacy download en_core_web_sm\n",
    "words = [item for item in uncleaned_words if item not in nlp.Defaults.stop_words]\n",
    "print(\"Words removed were: \", set(uncleaned_words).difference(set(words)))\n",
    "print(\"From\", len(uncleaned_words), \"to\", len(words))\n",
    "words_df = pd.DataFrame(words)\n",
    "words_df.columns = ['word']\n",
    "words_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words left after stemming was 29\n"
     ]
    }
   ],
   "source": [
    "stemmed_words = []\n",
    "ps = PorterStemmer()\n",
    "\n",
    "for w in words:\n",
    "    rootWord = ps.stem(w)\n",
    "    if rootWord not in stemmed_words:\n",
    "        stemmed_words.append(rootWord)\n",
    "        \n",
    "print(\"Number of words left after stemming was\", len(stemmed_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 spaCy's Pretained Vectors + Affinity Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tzemin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3337: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n",
      "c:\\users\\tzemin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:154: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  FutureWarning\n"
     ]
    }
   ],
   "source": [
    "def vectorize(text):\n",
    "    \"\"\"Get the SpaCy vector corresponding to a text\"\"\"\n",
    "    return nlp(text).vector\n",
    "\n",
    "X = np.stack(vectorize(word) for word in words)\n",
    "X_normalised = normalize(np.stack(vectorize(word) for word in words))\n",
    "\n",
    "affprop = AffinityPropagation()\n",
    "affprop.fit(X)\n",
    "\n",
    "word_array = np.array(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - *place:* attitude, cmpb, experience, nsf, patience, person, place, question, staff, time, tone\n",
      " - *check:* ask, check, help, rest, waste\n",
      " - *guards:* guards, hours, people, reviews\n",
      " - *nice:* bad, complete, friendly, good, great, kind, nice, professional, rude\n"
     ]
    }
   ],
   "source": [
    "for cluster_id in np.unique(affprop.labels_):\n",
    "    exemplar = word_array[affprop.cluster_centers_indices_[cluster_id]]\n",
    "    cluster = np.unique(word_array[np.nonzero(affprop.labels_==cluster_id)])\n",
    "    cluster_str = \", \".join(cluster)\n",
    "    print(\" - *%s:* %s\" % (exemplar, cluster_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster</th>\n",
       "      <th>Elements</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>staff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>personal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>guards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>doctors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>148</td>\n",
       "      <td>whole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>149</td>\n",
       "      <td>process</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>150</td>\n",
       "      <td>take</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>151</td>\n",
       "      <td>august</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>152</td>\n",
       "      <td>pigs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>197 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cluster  Elements\n",
       "0          1     staff\n",
       "1          1    person\n",
       "2          1  personal\n",
       "3          1    guards\n",
       "4          1   doctors\n",
       "..       ...       ...\n",
       "192      148     whole\n",
       "193      149   process\n",
       "194      150      take\n",
       "195      151    august\n",
       "196      152      pigs\n",
       "\n",
       "[197 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "labels_true_df = pd.read_csv(\"../../output/evaluation/cluster_manual.csv\")\n",
    "labels_true_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_cluster</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>staff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>guards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>place</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>hours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>rude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>friendly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>kind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6</td>\n",
       "      <td>great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6</td>\n",
       "      <td>nice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7</td>\n",
       "      <td>professional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8</td>\n",
       "      <td>experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11</td>\n",
       "      <td>check</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>12</td>\n",
       "      <td>waste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16</td>\n",
       "      <td>patience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>17</td>\n",
       "      <td>people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>attitude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20</td>\n",
       "      <td>help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>reviews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>nsf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>26</td>\n",
       "      <td>complete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>27</td>\n",
       "      <td>ask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>33</td>\n",
       "      <td>tone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>34</td>\n",
       "      <td>cmpb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>40</td>\n",
       "      <td>rest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    true_cluster          word\n",
       "0              1         staff\n",
       "1              1        person\n",
       "2              1        guards\n",
       "3              3         place\n",
       "4              4          time\n",
       "5              4         hours\n",
       "6              5          rude\n",
       "7              5      friendly\n",
       "8              5          kind\n",
       "9              6          good\n",
       "10             6         great\n",
       "11             6          nice\n",
       "12             7  professional\n",
       "13             8    experience\n",
       "14            11         check\n",
       "15            12           bad\n",
       "16            12         waste\n",
       "17            16      patience\n",
       "18            17        people\n",
       "19            19      attitude\n",
       "20            20      question\n",
       "21            20          help\n",
       "22            22       reviews\n",
       "23            23           nsf\n",
       "24            26      complete\n",
       "25            27           ask\n",
       "26            33          tone\n",
       "27            34          cmpb\n",
       "28            40          rest"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_true_df.columns = [\"true_cluster\", \"word\"]\n",
    "labels_true_df = pd.merge(labels_true_df, words_df, on = \"word\", how = \"inner\")\n",
    "labels_true_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(words_df['word']).difference(set(labels_true_df['word']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 3 2 0 0 3 0 0 3 0 1 3 3 1 1 0 2 3 3 0 3 0 0 2 1 1 3 0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_cluster</th>\n",
       "      <th>word</th>\n",
       "      <th>pred_cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>staff</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>person</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>guards</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>place</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>time</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>hours</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>rude</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>friendly</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>kind</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "      <td>good</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6</td>\n",
       "      <td>great</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6</td>\n",
       "      <td>nice</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7</td>\n",
       "      <td>professional</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8</td>\n",
       "      <td>experience</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11</td>\n",
       "      <td>check</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12</td>\n",
       "      <td>bad</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>12</td>\n",
       "      <td>waste</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16</td>\n",
       "      <td>patience</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>17</td>\n",
       "      <td>people</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>attitude</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>question</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20</td>\n",
       "      <td>help</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>reviews</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>nsf</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>26</td>\n",
       "      <td>complete</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>27</td>\n",
       "      <td>ask</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>33</td>\n",
       "      <td>tone</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>34</td>\n",
       "      <td>cmpb</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>40</td>\n",
       "      <td>rest</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    true_cluster          word  pred_cluster\n",
       "0              1         staff             0\n",
       "1              1        person             2\n",
       "2              1        guards             3\n",
       "3              3         place             2\n",
       "4              4          time             0\n",
       "5              4         hours             0\n",
       "6              5          rude             3\n",
       "7              5      friendly             0\n",
       "8              5          kind             0\n",
       "9              6          good             3\n",
       "10             6         great             0\n",
       "11             6          nice             1\n",
       "12             7  professional             3\n",
       "13             8    experience             3\n",
       "14            11         check             1\n",
       "15            12           bad             1\n",
       "16            12         waste             0\n",
       "17            16      patience             2\n",
       "18            17        people             3\n",
       "19            19      attitude             3\n",
       "20            20      question             0\n",
       "21            20          help             3\n",
       "22            22       reviews             0\n",
       "23            23           nsf             0\n",
       "24            26      complete             2\n",
       "25            27           ask             1\n",
       "26            33          tone             1\n",
       "27            34          cmpb             3\n",
       "28            40          rest             0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(affprop.labels_)\n",
    "labels_pred_df = pd.DataFrame({'pred_cluster': affprop.labels_})\n",
    "labels_pred_df\n",
    "pd.merge(labels_true_df, labels_pred_df, left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_true = list(labels_true_df['true_cluster'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rand Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7167487684729064"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.rand_score(labels_true, affprop.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.020635683994229003"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.adjusted_rand_score(labels_true, affprop.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutual Information based scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0435904889302693"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.adjusted_mutual_info_score(labels_true, affprop.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Silhouette score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21163464"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.silhouette_score(X, affprop.labels_, metric='euclidean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calinski-Harabasz Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.084159232372821"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.calinski_harabasz_score(X, affprop.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Davies Bouldin Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4980370150395048"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.davies_bouldin_score(X, affprop.labels_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
