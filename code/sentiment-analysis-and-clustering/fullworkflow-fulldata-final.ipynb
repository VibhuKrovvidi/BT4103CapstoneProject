{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Workflow\n",
    "\n",
    "Feature extraction + Word embedding (only pretrained ones) + Clustering + Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Feature Extraction\n",
    "\n",
    "Already done, use the csv output from that instead of running the code again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.2.0.json: 128kB [00:00, 1.22MB/s]\n",
      "2021-03-26 01:21:26 INFO: Downloading default packages for language: en (English)...\n",
      "2021-03-26 01:21:27 INFO: File exists: C:\\Users\\TzeMin\\stanza_resources\\en\\default.zip.\n",
      "2021-03-26 01:21:35 INFO: Finished downloading models and saved to C:\\Users\\TzeMin\\stanza_resources.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\TzeMin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\TzeMin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\TzeMin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import regex\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import stanza\n",
    "stanza.download('en') # download English model\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from sklearn.cluster import KMeans\n",
    "from tqdm import tqdm\n",
    "from gensim.models import Word2Vec \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import normalize\n",
    "import spacy\n",
    "from nltk.stem import PorterStemmer\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ippt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ipt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sessions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>still</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1766</th>\n",
       "      <td>vary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1767</th>\n",
       "      <td>mailbox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1768</th>\n",
       "      <td>forsee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1769</th>\n",
       "      <td>save</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1770</th>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1771 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index\n",
       "0         ippt\n",
       "1          ipt\n",
       "2     sessions\n",
       "3        still\n",
       "4           rt\n",
       "...        ...\n",
       "1766      vary\n",
       "1767   mailbox\n",
       "1768    forsee\n",
       "1769      save\n",
       "1770       win\n",
       "\n",
       "[1771 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refined = pd.read_csv(\"../../output/corpus-refined-features.csv\", usecols = ['index'])\n",
    "refined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           ippt\n",
       "1            ipt\n",
       "2       sessions\n",
       "3          still\n",
       "4             rt\n",
       "          ...   \n",
       "1766        vary\n",
       "1767     mailbox\n",
       "1768      forsee\n",
       "1769        save\n",
       "1770         win\n",
       "Name: index, Length: 1771, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncleaned_words = refined['index']\n",
    "uncleaned_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words removed were:  {'serious', 'everything', 'everyone', 'move', 'wherein', 'used', 'others', 'amount', 'still', 'somewhere', 'nothing', 'full', 'much', 'see', 'mine', 'give', 'call', 'next', 'part', 'anyone', 'becomes', 'put', 'yet', 'anything', 'go', 'latter', 'say', 'first', 'seem', 'nobody', 'alone', 'something', 'side', 'show', 'whole', 'get', 'enough', 'take', 'never', 'name', 'last', 'many', 'one', 'someone', 'become', 'keep', 'make', 'back', 'ten', 'none', 'top', 'less'}\n",
      "From 1771 to 1719\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ippt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ipt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sessions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>window</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1714</th>\n",
       "      <td>vary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1715</th>\n",
       "      <td>mailbox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1716</th>\n",
       "      <td>forsee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1717</th>\n",
       "      <td>save</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1718</th>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1719 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          word\n",
       "0         ippt\n",
       "1          ipt\n",
       "2     sessions\n",
       "3           rt\n",
       "4       window\n",
       "...        ...\n",
       "1714      vary\n",
       "1715   mailbox\n",
       "1716    forsee\n",
       "1717      save\n",
       "1718       win\n",
       "\n",
       "[1719 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\") # to run on command prompt: python -m spacy download en_core_web_sm\n",
    "words = [item for item in uncleaned_words if item not in nlp.Defaults.stop_words]\n",
    "\n",
    "print(\"Words removed were: \", set(uncleaned_words).difference(set(words)))\n",
    "print(\"From\", len(uncleaned_words), \"to\", len(words))\n",
    "\n",
    "words_df = pd.DataFrame(words)\n",
    "words_df.columns = ['word']\n",
    "words_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Word Embedding + Clustering + Evaluation\n",
    "\n",
    "- a higher Silhouette Coefficient score relates to a model with better defined clusters; the score is bounded between -1 for incorrect clustering and +1 for highly dense clustering. Scores around zero indicate overlapping clusters.\n",
    "- a higher Calinski-Harabasz score relates to a model with better defined clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 spaCy's Pretained Vectors + Affinity Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tzemin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3337: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n",
      "c:\\users\\tzemin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:154: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  FutureWarning\n"
     ]
    }
   ],
   "source": [
    "def vectorize(text):\n",
    "    \"\"\"Get the SpaCy vector corresponding to a text\"\"\"\n",
    "    return nlp(text).vector\n",
    "\n",
    "X = np.stack(vectorize(word) for word in words)\n",
    "X_normalised = normalize(np.stack(vectorize(word) for word in words))\n",
    "\n",
    "affprop = AffinityPropagation()\n",
    "affprop.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no. of clusters:  125\n",
      " - *dont:* cant, didnt, doesnt, dont, havent, wont\n",
      " - *complete:* birdy, clean, clear, complete, correct, exempt, liable, open, qualify, select, sorry, strict, suitable\n",
      " - *long:* bully, early, far, hard, kinda, late, long, mcs, nsdotsg, overseas, rly, worst\n",
      " - *days:* days, hours, months, thanks, times, ways, weeks, years\n",
      " - *good:* advisable, bad, brief, compulsory, cool, curious, dependent, different, dusty, fine, funny, good, great, green, haiz, incamp, mandatory, maximum, meaningful, mindef, miserable, nice, present, proactive, public, regular, right, siong, stringent, tough, true, useless, vague, weird, wrong\n",
      " - *week:* april, bit, day, december, hour, july, june, month, night, november, time, way, week, weekend, year\n",
      " - *letter:* abuse, background, base, bill, blur, butt, concern, cookhouse, degree, direction, division, dun, experience, eye, factor, fi, force, incident, job, kana, kit, language, letter, mission, mob, moi, mustache, period, prep, privilege, programme, quiz, rate, rod, role, route, rush, session, siao, site, slot, solution, station, system, tip, wah, waiver, zone\n",
      " - *mr:* mr, sia, sir\n",
      " - *thats:* hdb, hows, im, ns, tahan, thats, theres, whats\n",
      " - *pay:* abit, amend, clock, cover, dec, drag, earn, enjoy, garang, implement, keng, knock, pay, ps, roll, send, shit, singpass, teach, win, write\n",
      " - *park:* bmtc, buay, chest, deployment, error, fee, grenade, heart, helpdesk, mailbox, op, park, press, proficiency, query, ranger, scenario, screen, script, setup, soldier, staff, stance, status, tcss, unit\n",
      " - *kind:* kind, sort\n",
      " - *questions:* arrangements, benefits, cases, chances, conditions, criteria, details, differences, instructions, items, keys, lots, opportunities, personnel, personnels, problems, questions, reasons, secs, signs, specs, standards, tags, things, tights, venues, versions, vocations, weekends, wheels, words\n",
      " - *report:* announce, answer, appeal, arrange, bookout, capture, cause, centre, change, claim, confuse, crowd, delay, doubt, dude, end, fear, fix, guarantee, help, hope, lesson, limit, matter, note, notice, pang, place, practice, range, recruit, report, result, review, sign, study, summary, tally, test, use, view\n",
      " - *information:* access, action, activity, alot, announcement, anxiety, attention, attitude, authority, blood, cancellation, completion, confidence, confusion, correction, diagnosis, difference, difficulty, exemption, exit, extension, failure, flexibility, food, information, initiative, interest, leadership, life, money, notification, patience, payment, peace, penalty, placement, power, proof, punishment, purpose, responsibility, section, shortage, speculation, trial, trip, trouble, weather\n",
      " - *advice:* activation, address, advice, allowance, application, case, chance, checkup, clarification, consideration, date, decision, effect, effort, fallout, goal, idea, incentive, indication, info, intensity, nssc, obligation, opinion, opportunity, option, order, participation, pattern, performance, permission, pressure, question, reason, source, statement, strength, suggestion, topic, vocation, word\n",
      " - *heard:* got, heard, meant, saw, thought, wanted\n",
      " - *cos:* cos\n",
      " - *saturday:* bday, everyday, friday, saturday, sunday, thursday, tomorrow, weekday\n",
      " - *big:* average, big, close, common, direct, electronic, familiar, high, important, impossible, knowledgeable, logical, low, meaningless, mental, new, normal, old, optional, portal, professional, rare, severe, similar, small, spare, subjective, temporary, uni, warm\n",
      " - *meet:* act, arrive, avoid, calander, clarify, compare, defer, eg, fight, focus, forsee, happen, increase, login, look, lose, manage, meet, participate, reap, register, reset, resume, return, rmb, sleep, solve, stand, stop, survive, verify, waive, walk, zzzz\n",
      " - *total:* airforce, bt, chao, hong, hsp, mon, ooc, outdoor, overstress, pax, round, screenshot, sian, spf, standard, toh, total, uniform, yea\n",
      " - *higher:* better, easier, higher, lesser, newer, older, smaller, tougher, worse\n",
      " - *conduct:* assist, attempt, block, catch, charge, conduct, drive, edit, enrollment, excuse, fault, gain, grant, greent, inform, luck, parking, pop, punish, pushup, regret, release, resort, retake, rule, shift, squeeze, update, visit, waste\n",
      " - *individual:* anal, black, blue, chi, english, fri, individual, inpro, key, manual, medical, mobile, official, sial, simple, special\n",
      " - *silver:* ass, beard, biz, carpark, chiong, cny, confinement, ext, frequency, fun, future, gold, journey, laptop, length, light, magic, navy, nsman, outfield, ptis, record, sergeant, silver, singapore\n",
      " - *commanders:* bands, brothers, clothes, commanders, concerns, degrees, documents, downpes, fingers, forces, friends, holders, liabilities, liddat, lights, lockers, males, members, missions, moderators, oots, options, police, protocols, semesters, servicemen, slippers, specialists, sports, studies, trainers\n",
      " - *sense:* course, example, fact, moment, point, sense\n",
      " - *run:* bah, beat, bro, come, cso, cut, hq, ite, jog, live, offset, pti, read, relax, rem, rotate, run, sat, scdf, screw, sept, shot, sit, specialise, spread, straighten, streamline, turn\n",
      " - *reservists:* actions, areas, arms, belongings, bookings, boots, bros, camps, casualties, choices, commitments, defaulters, facilities, grades, ideas, instructors, ippts, ipts, issues, jobs, machines, offences, ones, opinions, organisations, palms, phones, posts, programs, pushups, rates, requirements, reservists, resources, services, shoes, systems, takers, targets, toilets, tracks, trainees, trainings, types, zones\n",
      " - *confident:* able, afraid, akin, applicable, confident, free, happy, ready, sure, unable, unlucky, willing\n",
      " - *fb:* bo, co, ex, fb, fr, id, ok, sf, sgt\n",
      " - *apart:* alrdy, apart, away, forward, later\n",
      " - *support:* bug, circuit, comment, condition, contact, control, convince, default, demand, diploma, directive, encounter, entitlement, exchange, feed, form, guardhouse, guideline, harm, impact, maximise, plan, position, posture, request, situation, stress, support, transport, travel, trust, version, weakness\n",
      " - *ground:* app, asa, bedok, booklet, cham, chiongsua, cost, ground, hiit, hks, hta, ihl, ipt, lah, ppt, scs, suay\n",
      " - *yo:* tt, ya, yo\n",
      " - *complain:* advise, aim, apr, ask, assume, believe, cb, click, complain, determine, discuss, feel, forget, hearsay, know, leap, niang, pray, remain, require, suppose, tell, thank, think, wait, wonder, worry, wose\n",
      " - *noob:* dk, ft, noob, nov, req, saf, tho, yr\n",
      " - *cleared:* answered, asked, attended, aussie, booked, cancelled, checked, chose, cleared, counted, gotten, granted, hit, idti, launched, left, noted, posted, received, sent, set, shut, stated, told, tried, ulu\n",
      " - *fy:* af, btw, fy, half, nv, ren\n",
      " - *starts:* affects, applies, clears, closes, coincides, falls, keeps, lets, means, mins, passes, pays, pts, reaches, regards, reminders, reopens, replies, reps, rumours, safra, shows, sounds, starts, stays, sucks, tells, understands, updates, works\n",
      " - *account:* account, care, diam, fcc, gpmg, input, insight, kena, mark, mask, mth, nsti, occifer, pen, pt, reckon, rt, span, sth, tag, volunteer\n",
      " - *closed:* closed, concerned, confused, coy, disabled, pleased, scan, scared, situp, stuck, worried\n",
      " - *fug:* bmt, boy, dunno, fug, gagt, gng, goodbye, height, hell, hotline, locker, nth, ot, pc, tbh, tio, wan\n",
      " - *fk:* ah, fk, huh, quote, va, xxx\n",
      " - *smart:* absent, appropriate, aware, certain, comfortable, complex, confidential, convenient, easy, effective, eligible, equivalent, fair, friendly, human, indoor, intense, ippt, likely, lucky, muslim, nervous, obvious, popular, positive, private, progressive, prone, proud, random, religious, rude, salty, short, sick, slow, smart, superior, unfair, unlikely, valid, wise, worth\n",
      " - *environment:* admin, age, army, bag, bed, boat, body, book, borderline, cd, commander, company, environment, ffi, group, guy, house, income, joke, loophole, man, marksman, max, nsfs, office, phase, photo, ppls, problem, process, recuit, requirement, salary, scheme, spy, story, thing, thread, thrgh, virus, wallet\n",
      " - *fire:* attendance, batches, board, brain, cert, choice, command, doc, eligibility, email, enlistee, exercise, fire, gg, issue, jiak, liao, list, manpower, norm, policy, reminder, rep, taiji, target, thumb, tone\n",
      " - *qn:* oc, qn, sg\n",
      " - *hearing:* booking, feeling, gathering, hearing, manning, meaning, opening, packing, scheduling, screening, thinking, timing, training, understanding, upping, wellbeing\n",
      " - *hear:* accept, achieve, allow, consider, expect, find, guess, hear, indicate, learn, let, maintain, promote, receive, remember, suggest, tend, try, want, wear\n",
      " - *fulfilled:* agreed, attempted, defaulted, enhanced, failed, fked, fulfilled, guaranteed, mred, phased, submitted, updated, waited, waived, wasted\n",
      " - *perform:* add, affect, apply, appt, attain, bother, bring, cancel, carry, commit, comply, count, create, die, eat, enter, face, fall, fccs, grow, hold, join, leave, lock, pass, perform, pick, play, prepare, provide, push, reach, rec, recover, refer, remove, repeat, respond, rest, reveal, save, serve, shag, shower, smoke, speak, submit, throw, treat, wish\n",
      " - *experts:* boys, companies, doctors, experts, folks, guys, injuries, kinds, men, officers, parents, people, pros, redditors, seniors, sergeants, soldiers, stations, students, superiors, units, verifies\n",
      " - *cock:* arrangement, bot, buddy, cock, covid, duno, enlistment, fate, gradient, grey, handful, keyword, lenient, loh, male, nsportal, obese, ofc, psychiatrist, qns, queue, rank, reservist, sound, tot, trooper, unsure\n",
      " - *deal:* activate, ba, backside, band, batch, benefit, blame, bravo, bunk, check, chill, classify, deal, declare, den, dey, drill, drink, drop, enlist, enrol, goodie, guard, habit, jan, kick, lie, link, log, mate, mindset, offer, opt, ord, outcome, patch, ppl, recourse, reward, ring, slack, stick, talk, train, undergo, vibrate, vote, wash, wat, wave, whack, work\n",
      " - *platoonmate:* allocate, calculate, collect, convert, counter, express, fit, gatecrash, generate, impt, intake, notify, parrot, platoonmate, seperate, sgts, shiong, void\n",
      " - *soc:* ankle, buibui, cadet, chiu, chop, commando, couple, cpf, feb, friend, fulfil, gym, icon, ict, inconvenience, lan, leh, lumber, mat, ndu, offender, oot, soc, tekan, timer, trainee, trainer\n",
      " - *makan:* fiit, makan, probably\n",
      " - *unreasonable:* available, busy, dumb, helpful, infectious, interested, lazy, obligatory, payable, possible, reliable, safe, stupid, tired, unavailable, unreasonable, unsafe, upcoming, useful, usual, yellow\n",
      " - *bleed:* bleed, cdf, dig, fbo, finish, forgot, iq, ive, kang, legit, mp, msg, need, pes, ptp, saikang, sar, suffer, switch, wtf\n",
      " - *steps:* ans, appointments, awards, beards, cents, commences, courses, explosives, fees, games, incentives, lessons, mths, nsmen, ops, points, statistics, steps, thou, timings, tips, tons, weekdays, windows\n",
      " - *water:* aiya, appointment, banner, birthday, branch, breakfast, callup, camera, car, cash, cat, category, certificate, citizen, cmi, color, computer, consultation, credit, duration, duty, family, fuel, home, image, line, lunch, machine, majority, ministry, mri, news, oct, offence, paper, pity, program, road, schedule, school, shirt, siam, state, sun, university, video, war, water, website, weight\n",
      " - *whichever:* whichever\n",
      " - *foot:* attire, bdae, burden, button, camp, chain, colour, foot, google, govt, guardroom, hand, head, jin, jun, level, llst, lor, maju, mind, motorbike, ocs, pack, paradise, paynow, pouch, prob, protocol, reply, rifle, rsaf, satisfy, scgp, scope, search, share, simi, sop, speed, store, supply, title, toilet, touch, type, yrs\n",
      " - *cpl:* alr, cpl, defaulter, ie, malays, medic, plenty, swee, tmr, zzz\n",
      " - *planning:* assuming, clearing, closing, counting, facing, meeting, passing, planning, reaching, reopening, risking, sleeping, taking, undergoing, warning, wondering\n",
      " - *purposes:* activities, balls, cadets, cancellations, changes, comments, congrats, consequences, cycles, events, excuses, experiences, guards, hands, lines, locations, macdonals, mates, mcdonalds, measures, obligations, orns, packs, pants, peers, pictures, places, prayers, purposes, recruits, results, rts, scholarships, sessions, skills, sums, tests, thurs, ups\n",
      " - *pretend:* agree, appreciate, attend, bmi, choose, confirm, continue, decide, detect, disrupt, extend, fail, follow, handle, hate, ignore, imagine, intend, ish, mean, mention, miss, pretend, prevent, profile, prove, realise, recommend, reflect, reject, relate, seek, start, stay, suck, understand, vary, wake, watch, welcome, workyear\n",
      " - *tuition:* accident, aerobics, anybody, area, article, brother, bus, culture, distance, doctor, employer, equipment, everybody, football, game, kranji, liability, lifestyle, lot, mail, mc, memo, message, nation, number, officer, person, phone, platform, security, service, term, tuition\n",
      " - *research:* approach, auto, award, balance, basis, combat, confirmation, cycle, deadline, defence, diff, driver, education, entrance, exception, feedback, fitness, flag, infantry, injury, instructor, interview, lack, location, loss, maintenance, march, nonsense, pace, page, pain, picture, platoon, print, promotion, quota, reschedule, research, response, resumption, risk, safety, score, selection, shape, spot, stadium, step, stuff, track, vacancy, window, workout, wsdip\n",
      " - *sch:* abt, ar, bu, ck, damn, ic, la, lk, okay, osa, sch, ur, wa\n",
      " - *jc:* bp, jc, lo\n",
      " - *parliament:* cisco, clerk, cmpb, expert, fark, government, hair, heng, instruction, khatib, min, morale, nsf, parliament, regimentation, relief, shelter, specialist, student\n",
      " - *qualifies:* allowances, answers, attempts, bags, bookouts, breaks, bunks, burpees, charges, colours, commandos, conducts, counts, dates, defines, doubts, exercises, forms, gloves, icts, knots, lectures, matters, medals, muslims, outfields, peeps, plans, pullups, qualifies, records, regulars, reports, reviews, rewards, rounds, sets, sibei, slots, sms, stars, states, workouts\n",
      " - *begins:* allows, begins, depends, ends, fails, feels, happens, isnt, knows, needs, opens\n",
      " - *fare:* aug, db, define, discharge, endorse, enquire, escalate, escape, fare, february, fuck, fulfill, highlight, hrs, kenna, le, lead, mo, natalie, newbie, nightmare, nvm, oic, peer, pew, pm, post, shoot, skip, slip, tick, trick, xiong\n"
     ]
    }
   ],
   "source": [
    "word_array = np.array(words)\n",
    "print(\"Total no. of clusters: \", len(affprop_glove.cluster_centers_indices_))\n",
    "for cluster_id in np.unique(affprop.labels_):\n",
    "    exemplar = word_array[affprop.cluster_centers_indices_[cluster_id]]\n",
    "    cluster = np.unique(word_array[np.nonzero(affprop.labels_==cluster_id)])\n",
    "    cluster_str = \", \".join(cluster)\n",
    "    print(\" - *%s:* %s\" % (exemplar, cluster_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation\n",
    "\n",
    "- Silhouette score\n",
    "- Calinski Harabasz index\n",
    "- Davies Bouldin index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette score: 0.025242906\n",
      "Calinski Harabasz: 28.82584207818853\n",
      "Davies Bouldin: 2.91456112363272\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Silhouette score:\", metrics.silhouette_score(X, affprop.labels_, metric='euclidean'))\n",
    "print(\"Calinski Harabasz:\", metrics.calinski_harabasz_score(X, affprop.labels_))\n",
    "print(\"Davies Bouldin:\", metrics.davies_bouldin_score(X, affprop.labels_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 GloVe's Pretrained Vectors + Affinity Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# progress bar\n",
    "def progress(count, total, status=''):\n",
    "    bar_len = 60\n",
    "    filled_len = int(round(bar_len * count / float(total)))\n",
    "    percents = round(100.0 * count / float(total), 1)\n",
    "    bar = '=' * filled_len + '-' * (bar_len - filled_len)\n",
    "    sys.stdout.write('[%s] %s%s ...%s\\r' % (bar, percents, '%', status))\n",
    "    sys.stdout.flush() \n",
    "\n",
    "# load dictionary of word vectors based on pretrained Glove model\n",
    "def loadGloveDict(File):\n",
    "    print(\"Loading glove model\")\n",
    "    f = open(File, 'r', encoding = 'utf-8')\n",
    "    gloveDict = {}\n",
    "    i = 0\n",
    "    for line in f:\n",
    "        splitLine = line.split()\n",
    "        word = splitLine[0]\n",
    "        progress(i, 400000, status = 'retreiving vectors')\n",
    "        wordEmbedding = pd.DataFrame([float(value) for value in splitLine[1:]]).T\n",
    "        gloveDict[word] = wordEmbedding\n",
    "        i += 1\n",
    "    print(len(gloveDict), \"words loaded\")\n",
    "    return gloveDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading glove model\n",
      "400000 words loaded==========================================] 100.0% ...retreiving vectors\n"
     ]
    }
   ],
   "source": [
    "model = loadGloveDict(\"../glove.6B/glove.6B.300d.txt\") #pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[============================================================] 100.0% ...concatenating extracted vectors\r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ipt</td>\n",
       "      <td>-0.264510</td>\n",
       "      <td>0.418580</td>\n",
       "      <td>0.210640</td>\n",
       "      <td>0.30751</td>\n",
       "      <td>-0.038163</td>\n",
       "      <td>0.413510</td>\n",
       "      <td>-0.21860</td>\n",
       "      <td>0.128270</td>\n",
       "      <td>-0.008734</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.17047</td>\n",
       "      <td>-0.311660</td>\n",
       "      <td>-0.24170</td>\n",
       "      <td>0.287430</td>\n",
       "      <td>-0.371740</td>\n",
       "      <td>-0.357100</td>\n",
       "      <td>0.212920</td>\n",
       "      <td>0.105580</td>\n",
       "      <td>0.304500</td>\n",
       "      <td>-0.542100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sessions</td>\n",
       "      <td>-0.509840</td>\n",
       "      <td>0.008746</td>\n",
       "      <td>-0.102280</td>\n",
       "      <td>0.37741</td>\n",
       "      <td>0.162980</td>\n",
       "      <td>-0.507320</td>\n",
       "      <td>-0.15894</td>\n",
       "      <td>-0.317470</td>\n",
       "      <td>0.233890</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.29631</td>\n",
       "      <td>-0.322150</td>\n",
       "      <td>-0.81685</td>\n",
       "      <td>-0.086836</td>\n",
       "      <td>-0.289170</td>\n",
       "      <td>0.483030</td>\n",
       "      <td>-0.213460</td>\n",
       "      <td>-0.369050</td>\n",
       "      <td>-0.051946</td>\n",
       "      <td>0.011276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rt</td>\n",
       "      <td>-0.097004</td>\n",
       "      <td>-0.874420</td>\n",
       "      <td>-0.087863</td>\n",
       "      <td>-0.27042</td>\n",
       "      <td>-0.524880</td>\n",
       "      <td>0.051912</td>\n",
       "      <td>-0.49371</td>\n",
       "      <td>0.497150</td>\n",
       "      <td>-0.002542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.39796</td>\n",
       "      <td>0.042912</td>\n",
       "      <td>-0.12752</td>\n",
       "      <td>0.124230</td>\n",
       "      <td>-0.435650</td>\n",
       "      <td>0.032578</td>\n",
       "      <td>0.013193</td>\n",
       "      <td>0.190810</td>\n",
       "      <td>0.464680</td>\n",
       "      <td>0.597970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>window</td>\n",
       "      <td>-0.029352</td>\n",
       "      <td>-0.137720</td>\n",
       "      <td>-0.197070</td>\n",
       "      <td>-0.79303</td>\n",
       "      <td>0.146030</td>\n",
       "      <td>0.563230</td>\n",
       "      <td>-0.49493</td>\n",
       "      <td>-0.610630</td>\n",
       "      <td>-0.086160</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.10082</td>\n",
       "      <td>0.076632</td>\n",
       "      <td>-0.17503</td>\n",
       "      <td>0.110900</td>\n",
       "      <td>0.418830</td>\n",
       "      <td>0.296150</td>\n",
       "      <td>-0.233930</td>\n",
       "      <td>0.399510</td>\n",
       "      <td>0.167900</td>\n",
       "      <td>0.456090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>book</td>\n",
       "      <td>0.048733</td>\n",
       "      <td>-0.055083</td>\n",
       "      <td>0.149470</td>\n",
       "      <td>-0.11269</td>\n",
       "      <td>0.098791</td>\n",
       "      <td>0.543340</td>\n",
       "      <td>-0.51204</td>\n",
       "      <td>0.278820</td>\n",
       "      <td>0.114970</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.11647</td>\n",
       "      <td>-0.072080</td>\n",
       "      <td>-0.41821</td>\n",
       "      <td>0.392380</td>\n",
       "      <td>-0.017030</td>\n",
       "      <td>-0.031026</td>\n",
       "      <td>0.254280</td>\n",
       "      <td>0.513520</td>\n",
       "      <td>0.136670</td>\n",
       "      <td>-0.126390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1650</th>\n",
       "      <td>vary</td>\n",
       "      <td>-0.412140</td>\n",
       "      <td>-0.018634</td>\n",
       "      <td>0.048448</td>\n",
       "      <td>0.43328</td>\n",
       "      <td>-0.023861</td>\n",
       "      <td>0.495050</td>\n",
       "      <td>0.02622</td>\n",
       "      <td>0.761890</td>\n",
       "      <td>0.011218</td>\n",
       "      <td>...</td>\n",
       "      <td>0.11174</td>\n",
       "      <td>0.002409</td>\n",
       "      <td>-0.02948</td>\n",
       "      <td>0.143860</td>\n",
       "      <td>-0.013612</td>\n",
       "      <td>-0.296920</td>\n",
       "      <td>-0.573060</td>\n",
       "      <td>0.177610</td>\n",
       "      <td>0.294730</td>\n",
       "      <td>-0.350610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1651</th>\n",
       "      <td>mailbox</td>\n",
       "      <td>-0.500810</td>\n",
       "      <td>-0.125950</td>\n",
       "      <td>-0.717040</td>\n",
       "      <td>0.11644</td>\n",
       "      <td>0.212270</td>\n",
       "      <td>0.280370</td>\n",
       "      <td>-0.45449</td>\n",
       "      <td>-0.408650</td>\n",
       "      <td>-0.444210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.22481</td>\n",
       "      <td>0.119780</td>\n",
       "      <td>0.20767</td>\n",
       "      <td>-0.147620</td>\n",
       "      <td>-0.329880</td>\n",
       "      <td>-0.451520</td>\n",
       "      <td>0.621500</td>\n",
       "      <td>-0.174460</td>\n",
       "      <td>-0.331040</td>\n",
       "      <td>-0.341090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1652</th>\n",
       "      <td>forsee</td>\n",
       "      <td>0.013178</td>\n",
       "      <td>-0.235220</td>\n",
       "      <td>0.085450</td>\n",
       "      <td>-0.13470</td>\n",
       "      <td>0.277110</td>\n",
       "      <td>-0.255290</td>\n",
       "      <td>-0.40537</td>\n",
       "      <td>-0.002905</td>\n",
       "      <td>0.205280</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26494</td>\n",
       "      <td>-0.092792</td>\n",
       "      <td>0.95559</td>\n",
       "      <td>-0.131530</td>\n",
       "      <td>-0.184620</td>\n",
       "      <td>-0.299780</td>\n",
       "      <td>-0.377070</td>\n",
       "      <td>-0.046352</td>\n",
       "      <td>-0.174660</td>\n",
       "      <td>0.252760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>save</td>\n",
       "      <td>0.568290</td>\n",
       "      <td>0.101280</td>\n",
       "      <td>-0.839500</td>\n",
       "      <td>0.22182</td>\n",
       "      <td>0.019760</td>\n",
       "      <td>0.034984</td>\n",
       "      <td>-0.02562</td>\n",
       "      <td>0.253890</td>\n",
       "      <td>-0.193850</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.01707</td>\n",
       "      <td>0.041124</td>\n",
       "      <td>-0.14130</td>\n",
       "      <td>-0.140870</td>\n",
       "      <td>-0.123330</td>\n",
       "      <td>-0.448690</td>\n",
       "      <td>0.323660</td>\n",
       "      <td>-0.539140</td>\n",
       "      <td>0.351690</td>\n",
       "      <td>-0.295690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1654</th>\n",
       "      <td>win</td>\n",
       "      <td>0.205850</td>\n",
       "      <td>0.803290</td>\n",
       "      <td>-0.430850</td>\n",
       "      <td>-0.18265</td>\n",
       "      <td>-0.142220</td>\n",
       "      <td>0.090657</td>\n",
       "      <td>0.15399</td>\n",
       "      <td>0.128300</td>\n",
       "      <td>-0.036204</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.44922</td>\n",
       "      <td>0.166280</td>\n",
       "      <td>-0.23547</td>\n",
       "      <td>-0.031338</td>\n",
       "      <td>0.390820</td>\n",
       "      <td>0.142370</td>\n",
       "      <td>0.051430</td>\n",
       "      <td>-0.666200</td>\n",
       "      <td>-0.195790</td>\n",
       "      <td>0.141260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1655 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature         0         1         2        3         4         5  \\\n",
       "0          ipt -0.264510  0.418580  0.210640  0.30751 -0.038163  0.413510   \n",
       "1     sessions -0.509840  0.008746 -0.102280  0.37741  0.162980 -0.507320   \n",
       "2           rt -0.097004 -0.874420 -0.087863 -0.27042 -0.524880  0.051912   \n",
       "3       window -0.029352 -0.137720 -0.197070 -0.79303  0.146030  0.563230   \n",
       "4         book  0.048733 -0.055083  0.149470 -0.11269  0.098791  0.543340   \n",
       "...        ...       ...       ...       ...      ...       ...       ...   \n",
       "1650      vary -0.412140 -0.018634  0.048448  0.43328 -0.023861  0.495050   \n",
       "1651   mailbox -0.500810 -0.125950 -0.717040  0.11644  0.212270  0.280370   \n",
       "1652    forsee  0.013178 -0.235220  0.085450 -0.13470  0.277110 -0.255290   \n",
       "1653      save  0.568290  0.101280 -0.839500  0.22182  0.019760  0.034984   \n",
       "1654       win  0.205850  0.803290 -0.430850 -0.18265 -0.142220  0.090657   \n",
       "\n",
       "            6         7         8  ...      290       291      292       293  \\\n",
       "0    -0.21860  0.128270 -0.008734  ... -0.17047 -0.311660 -0.24170  0.287430   \n",
       "1    -0.15894 -0.317470  0.233890  ... -0.29631 -0.322150 -0.81685 -0.086836   \n",
       "2    -0.49371  0.497150 -0.002542  ...  0.39796  0.042912 -0.12752  0.124230   \n",
       "3    -0.49493 -0.610630 -0.086160  ... -0.10082  0.076632 -0.17503  0.110900   \n",
       "4    -0.51204  0.278820  0.114970  ... -0.11647 -0.072080 -0.41821  0.392380   \n",
       "...       ...       ...       ...  ...      ...       ...      ...       ...   \n",
       "1650  0.02622  0.761890  0.011218  ...  0.11174  0.002409 -0.02948  0.143860   \n",
       "1651 -0.45449 -0.408650 -0.444210  ...  0.22481  0.119780  0.20767 -0.147620   \n",
       "1652 -0.40537 -0.002905  0.205280  ... -0.26494 -0.092792  0.95559 -0.131530   \n",
       "1653 -0.02562  0.253890 -0.193850  ... -0.01707  0.041124 -0.14130 -0.140870   \n",
       "1654  0.15399  0.128300 -0.036204  ... -0.44922  0.166280 -0.23547 -0.031338   \n",
       "\n",
       "           294       295       296       297       298       299  \n",
       "0    -0.371740 -0.357100  0.212920  0.105580  0.304500 -0.542100  \n",
       "1    -0.289170  0.483030 -0.213460 -0.369050 -0.051946  0.011276  \n",
       "2    -0.435650  0.032578  0.013193  0.190810  0.464680  0.597970  \n",
       "3     0.418830  0.296150 -0.233930  0.399510  0.167900  0.456090  \n",
       "4    -0.017030 -0.031026  0.254280  0.513520  0.136670 -0.126390  \n",
       "...        ...       ...       ...       ...       ...       ...  \n",
       "1650 -0.013612 -0.296920 -0.573060  0.177610  0.294730 -0.350610  \n",
       "1651 -0.329880 -0.451520  0.621500 -0.174460 -0.331040 -0.341090  \n",
       "1652 -0.184620 -0.299780 -0.377070 -0.046352 -0.174660  0.252760  \n",
       "1653 -0.123330 -0.448690  0.323660 -0.539140  0.351690 -0.295690  \n",
       "1654  0.390820  0.142370  0.051430 -0.666200 -0.195790  0.141260  \n",
       "\n",
       "[1655 rows x 301 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numFeatures = len(words_df['word'])\n",
    "vectorlist = []\n",
    "notInCorpus = []\n",
    "\n",
    "for i in range(0, numFeatures):\n",
    "    progress(i, numFeatures - 1, status = \"concatenating extracted vectors\")\n",
    "    wordAsDF = words_df['word'][[i]]\n",
    "    try:\n",
    "        vector = pd.concat([wordAsDF, model[wordAsDF[i]].set_index(wordAsDF.index)], axis = 1)\n",
    "        vectorlist.append(vector)\n",
    "    except KeyError:\n",
    "        notInCorpus.append(wordAsDF[i])\n",
    "\n",
    "embeddings = pd.concat(vectorlist).reset_index(drop = True).rename(columns = {\"word\":\"feature\"})\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ippt',\n",
       " 'gagt',\n",
       " 'nsmen',\n",
       " 'inpro',\n",
       " 'cmpb',\n",
       " 'ipts',\n",
       " 'fccs',\n",
       " 'orns',\n",
       " 'covid',\n",
       " 'ippts',\n",
       " 'nsman',\n",
       " 'alrdy',\n",
       " 'hiit',\n",
       " 'greent',\n",
       " 'bday',\n",
       " 'workyear',\n",
       " 'mths',\n",
       " 'ppls',\n",
       " 'nsportal',\n",
       " 'ptis',\n",
       " 'tbh',\n",
       " 'liddat',\n",
       " 'occifer',\n",
       " 'nvm',\n",
       " 'downpes',\n",
       " 'calander',\n",
       " 'burpees',\n",
       " 'fiit',\n",
       " 'sibei',\n",
       " 'llst',\n",
       " 'singpass',\n",
       " 'nssc',\n",
       " 'situp',\n",
       " 'scgp',\n",
       " 'wsdip',\n",
       " 'suay',\n",
       " 'tcss',\n",
       " 'platoonmate',\n",
       " 'paynow',\n",
       " 'oots',\n",
       " 'req',\n",
       " 'redditors',\n",
       " 'bookouts',\n",
       " 'impt',\n",
       " 'nsti',\n",
       " 'chiongsua',\n",
       " 'tekan',\n",
       " 'recuit',\n",
       " 'gng',\n",
       " 'wose',\n",
       " 'thrgh',\n",
       " 'incamp',\n",
       " 'fked',\n",
       " 'bdae',\n",
       " 'nsdotsg',\n",
       " 'idti',\n",
       " 'macdonals',\n",
       " 'haiz',\n",
       " 'buibui',\n",
       " 'mred',\n",
       " 'saikang',\n",
       " 'pullups',\n",
       " 'jiak',\n",
       " 'buay']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notInCorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.64602977,  1.17045476,  0.70192671, ...,  0.47917534,\n",
       "         0.97753791, -1.49455437],\n",
       "       [-1.4082633 , -0.03487774, -0.31594748, ..., -0.86652199,\n",
       "        -0.12867643,  0.0841282 ],\n",
       "       [-0.12559325, -2.63229296, -0.2690515 , ...,  0.72082417,\n",
       "         1.47464943,  1.75786106],\n",
       "       ...,\n",
       "       [ 0.21673918, -0.75238859,  0.29470547, ...,  0.0484093 ,\n",
       "        -0.50951388,  0.77303879],\n",
       "       [ 1.94145683,  0.23726694, -2.71399559, ..., -1.34877061,\n",
       "         1.12398998, -0.79159079],\n",
       "       [ 0.81536576,  2.3018972 , -1.3847284 , ..., -1.70901818,\n",
       "        -0.5750899 ,  0.45494926]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc_X = StandardScaler()\n",
    "X_glove = sc_X.fit_transform(embeddings.iloc[:,1:])\n",
    "X_glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tzemin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:154: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AffinityPropagation()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "affprop_glove = AffinityPropagation()\n",
    "affprop_glove.fit(X_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no. of clusters:  125\n",
      " - *book:* april, better, board, book, chill, condition, contact, cycle, dates, defaulter, different, doubts, effect, fcc, form, ict, injuries, injury, meeting, mo, months, nightmare, nth, number, op, period, person, probably, pti, pushup, saw, slots, specialist, thats, trouble, units, ur, vague, weekday, weekend, yr\n",
      " - *years:* action, end, sunday, years\n",
      " - *sms:* accept, activate, attendance, beards, benefits, bill, bmt, cash, forgot, gng, goodie, guess, huh, instructor, lan, life, lines, macdonals, pretend, progressive, remain, request, scdf, seperate, sick, skills, smaller, sms, special, tally, volunteer, wait, wake\n",
      " - *nsmen:* nsmen\n",
      " - *mindef:* appointments, assume, camps, cant, cb, clear, command, cut, easy, enquire, fact, guys, ipt, jobs, mindef, obligations, oc, places, question, return, review, system, time, training, vocation, ways\n",
      " - *new:* boy, eg, jog, lessons, new, phones, wonder\n",
      " - *liao:* actions, button, cases, closes, cso, depends, detect, discuss, drink, dun, eligibility, enrol, extend, fix, forget, harm, hks, lah, le, level, liao, newbie, ocs, outdoor, patience, peers, portal, punishment, reps, short, soldier, solution, standard, subjective, sucks, thurs, tio, unlucky, work\n",
      " - *didnt:* busy, camera, color, didnt, doctors, hearsay, mcs, miserable, mobile, nvm, officer, opinion, ptis, start\n",
      " - *finish:* finish\n",
      " - *issue:* alr, bravo, buibui, collect, conducts, damn, explosives, gain, goal, head, idti, issue, maju, nssc, recuit, share, sian, version, workouts\n",
      " - *cycles:* cycles, instructors, meaningless, old, personnel, small, speed\n",
      " - *attend:* attend, confusion, den, nervous, park, pictures, record, response, services, siong, situation, tuition, wsdip\n",
      " - *reservist:* answer, ask, available, award, benefit, blood, chop, co, counts, date, drop, english, environment, everybody, ffi, fine, fire, foot, good, hearing, im, july, language, lead, mandatory, month, oot, orns, outfields, pt, quiz, realise, regards, reservist, rod, scholarships, sept, sial, spot, states, status, strength, stress, thing, thinking, type, understanding, update, visit, wrong, year, yo\n",
      " - *khatib:* appreciate, job, khatib\n",
      " - *far:* act, answered, bro, doubt, far, money, pattern, pm, regret, sibei, specs\n",
      " - *sent:* sent\n",
      " - *information:* information\n",
      " - *ipts:* aug, facilities, falls, ipts, meaningful, muslims, nonsense, regimentation, replies, sgts, shot, student, tell, va\n",
      " - *green:* bag, bah, complex, find, green, ish, leap, learn, repeat, sat, solve, timer, tough, travel\n",
      " - *age:* advise, age, gym, infantry, mr, ppls, quote, ups\n",
      " - *incentives:* high, incentives, security\n",
      " - *lot:* breaks, fuck, lot, morale, prepare, siam\n",
      " - *safra:* convert, gagt, safra\n",
      " - *stay:* af, allowances, appointment, big, black, bmi, category, chest, clerk, come, commander, counting, define, direct, direction, drill, duty, familiar, fear, gloves, grades, group, hsp, late, lazy, lets, male, maximise, medic, noob, nsdotsg, practice, recourse, register, result, spare, spf, starts, stay, systems, throw, tomorrow, versions, weeks, wose\n",
      " - *email:* doctor, email\n",
      " - *lor:* lor\n",
      " - *programme:* covid, programme, rsaf\n",
      " - *excuse:* excuse, join, likely, sgt, story, total\n",
      " - *default:* cadets, default, grow, outfield, survive, toilet, track, whichever\n",
      " - *news:* hrs, liable, news\n",
      " - *blue:* blue\n",
      " - *list:* list\n",
      " - *wah:* achieve, affect, answers, care, chiu, cmpb, coincides, fun, gotten, great, guarantee, guard, happy, house, indoor, items, kana, liability, login, mask, measures, mindset, muslim, page, paynow, picture, plenty, press, shortage, sir, speak, toilets, wah\n",
      " - *option:* apart, option\n",
      " - *fulfil:* bring, fulfil, guardroom, play, ptp, scgp, spread\n",
      " - *sia:* announcement, curious, sia\n",
      " - *fulfill:* excuses, fulfill, ite, mail, welcome\n",
      " - *nice:* case, nice\n",
      " - *website:* appt, kick, rly, website\n",
      " - *notification:* address, advice, akin, applies, apply, apr, arrangement, average, avoid, aware, ba, bad, bags, band, bands, bedok, body, bother, breakfast, bu, bully, bunks, butt, cents, cert, checkup, circuit, clears, cny, commitments, company, concern, confinement, congrats, cover, cpl, credit, culture, day, days, db, defaulted, delay, details, diagnosis, differences, discharge, dont, easier, eat, enlistment, equivalent, escalate, ex, example, exception, exemption, expect, experience, extension, face, fare, fit, game, guards, guideline, handful, hear, id, ie, imagine, impt, intend, interested, iq, key, kit, la, leh, lifestyle, line, location, look, loophole, lose, lucky, males, man, manning, mates, mc, mins, mri, msg, mustache, norm, notice, notification, nov, obese, offset, opens, participate, participation, peer, pen, people, plan, popular, post, private, privilege, programs, prone, qn, query, questions, quota, random, reason, regular, relax, ren, requirement, resort, risking, rt, saturday, sessions, setup, sf, shiong, simi, similar, sit, sleeping, slot, smoke, span, spy, sth, stick, study, suggest, tahan, temporary, test, topic, tot, train, trainer, trainings, trooper, undergo, understands, useless, vacancy, watch, week, weekends, window, wise, workout, write, zzz\n",
      " - *fall:* diff, fall, responsibility, sun, talk, uniform\n",
      " - *memo:* guy, memo, unable\n",
      " - *waive:* waive\n",
      " - *exercises:* count, exchange, exercises, future, natalie, rule, selection\n",
      " - *hq:* appeal, application, area, arrange, arrive, auto, brief, cool, diam, force, free, heart, hows, hq, keng, low, members, miss, mred, officers, parrot, platoon, policy, punish, read, recruits, req, satisfy, sch, severe, simple, staff, students, wear, wish, works\n",
      " - *commanders:* commanders, facing, google\n",
      " - *sports:* bp, route, sports, xxx\n",
      " - *beard:* beard, boat, cham, dk, exempt, express, fulfilled, heng, holders, human, incamp, indicate, kranji, mat, min, palms, parliament, pass, redditors, shape, specialise, stringent, thou, timings, wallet\n",
      " - *wash:* dude, govt, wash\n",
      " - *sense:* abt, admin, agree, aiya, anybody, approach, asked, attain, awards, batch, booking, bookouts, boots, cadet, cancellation, cancelled, car, carpark, cdf, chances, change, chi, clarify, closed, clothes, cock, conditions, consequences, convenient, correct, couple, crowd, december, defer, defines, diploma, duno, edit, effective, eligible, enrollment, entrance, expert, experts, fault, fee, feedback, feels, forces, fuel, goodbye, hair, haiz, ic, interview, ippt, jc, journey, jun, kena, kenna, kind, knows, later, letter, locations, log, manage, mark, means, mention, motorbike, night, normal, nsti, oct, offer, official, open, ot, patch, peace, phone, pity, placement, platoonmate, positive, possible, posted, ppt, prayers, professional, proficiency, profile, protocols, prove, psychiatrist, qualify, release, remember, report, reschedule, resume, reveal, roll, scheduling, section, send, sense, sergeants, session, set, shit, shoot, shower, shut, siao, sleep, standards, stays, stop, store, straighten, strict, sums, support, tells, think, thumb, touch, trainee, treat, trick, try, unit, waived, want, wat, weekdays, whack, worry, worse, xiong\n",
      " - *payment:* fccs, payment\n",
      " - *closing:* closing\n",
      " - *everyday:* everyday, navy, pick\n",
      " - *enlist:* ass, confirm, enlist, image, limit, place, wont\n",
      " - *serve:* serve\n",
      " - *workyear:* able, absent, abuse, accident, affects, ah, aim, allow, announce, ans, appropriate, arms, aussie, balance, begins, birdy, bmtc, bt, capture, certificate, chain, chao, companies, complain, continue, counter, decide, die, difficulty, dig, directive, documents, enter, fked, focus, fr, friday, funny, government, grant, habit, hell, helpdesk, helpful, highlight, hope, impossible, inconvenience, increase, inform, instruction, launched, lie, live, llst, locker, maximum, moderators, ord, packs, perform, point, power, ppl, problems, proud, public, ready, recover, recruit, rem, road, scenario, scope, seek, sergeant, sg, slip, sounds, stated, studies, summary, sure, switch, taiji, takers, thanks, thursday, tons, trust, university, upcoming, view, wan, warning, wheels, word, workyear, ya\n",
      " - *sort:* activation, coy, demand, purpose, sort, usual\n",
      " - *pc:* activity, anxiety, callup, check, clarification, clean, comment, comments, cost, defaulters, dusty, guardhouse, loh, magic, maintain, need, pace, pc, pew, problem, rank, situp, steps, unsafe\n",
      " - *confident:* confident\n",
      " - *dec:* dec, lockers, mcdonalds, weird\n",
      " - *phase:* degree, phase\n",
      " - *lo:* lo\n",
      " - *bunk:* aerobics, attempt, attempts, bday, bros, bunk, certain, changes, chiong, choices, classify, click, confirmation, declare, deployment, eye, fri, height, ignore, insight, issues, knowledgeable, meaning, meet, missions, ns, opening, overseas, proactive, purposes, queue, rates, reward, rotate, run, score, scs, skip, slow, smart, stupid, superior, suppose, targets, tick, times, types, unavailable, vote, weakness, worth, wtf, zone, zones\n",
      " - *light:* light\n",
      " - *process:* oic, process\n",
      " - *liddat:* bed, liddat, marksman, religious, thrgh, willing\n",
      " - *dumb:* amend, dumb, rec\n",
      " - *occifer:* abit, add, army, balls, batches, bdae, belongings, birthday, blame, block, brother, bus, camp, cat, cisco, citizen, clock, commandos, consider, consideration, control, create, degrees, duration, effort, enjoy, events, factor, feel, fitness, flag, friend, gg, half, hard, hour, ihl, important, incentive, individual, inpro, instructions, ippts, jin, joke, keyword, lenient, let, liabilities, link, long, lumber, machine, machines, makan, matters, max, men, mon, note, nsman, occifer, older, order, pack, passing, peeps, penalty, pes, position, program, protocol, pts, reap, reminder, rep, resources, results, retake, rewards, rounds, saf, safety, scan, schedule, select, seniors, shag, slack, stand, state, suffer, target, tekan, term, tho, title, true, unlikely, upping, useful, waste, yrs\n",
      " - *obvious:* obvious\n",
      " - *police:* police\n",
      " - *rude:* rate, rude, thread\n",
      " - *thought:* access, failed, fair, ft, idea, performance, points, pop, silver, things, thought, trainees\n",
      " - *pressure:* pressure, wondering\n",
      " - *proof:* laptop, paradise, proof\n",
      " - *ground:* ground\n",
      " - *tags:* dunno, lesser, specialists, tags, wa\n",
      " - *keys:* keys\n",
      " - *booklet:* booklet\n",
      " - *optional:* offence, optional\n",
      " - *require:* concerns, require\n",
      " - *criteria:* allocate, attended, carry, charge, criteria, disrupt, fingers, flexibility, forward, hand, havent, intense, knots, message, ministry, mp, nation, nv, packing, pain, promote, rare, reply, saikang\n",
      " - *driver:* borderline, driver, virus\n",
      " - *suck:* suck\n",
      " - *colours:* attempted, colours, equipment, ulu, waiver, windows\n",
      " - *tip:* common, march, tip\n",
      " - *concerned:* concerned\n",
      " - *infectious:* infectious, ooc\n",
      " - *comply:* airforce, comply, early, fails, mean, offences, posture, ring, screen, secs, shirt, sound, toh, wellbeing\n",
      " - *ends:* casualties, cpf, ends, enhanced, exercise, fb, friendly, got, ive, kinda, logical, meant, mission, needs, qualifies, service, tests, theres, tights, tried, water\n",
      " - *reflect:* reflect\n",
      " - *electronic:* electronic, hold, reservists, risk\n",
      " - *void:* afraid, allowance, allows, alrdy, anal, app, ar, areas, arrangements, asa, attire, base, booked, bot, brain, branch, burden, calander, centre, choice, chose, commit, confidence, cookhouse, cos, courses, determine, dey, doc, doesnt, downpes, education, error, escape, fail, failure, fark, fate, fbo, football, friends, games, garang, grenade, hands, happens, heard, higher, home, hong, hotline, hta, icon, initiative, intensity, isnt, lectures, legit, lesson, lights, lots, maintenance, mate, ndu, newer, november, nsportal, obligatory, ofc, ones, opt, organisations, parking, pax, personnels, plans, pleased, present, promotion, provide, receive, refer, research, rest, reviews, rmb, rush, salty, scared, school, screenshot, screw, shift, singpass, soc, stadium, statement, station, statistics, stuff, submitted, swee, tcss, timing, told, tone, trip, uni, updated, venues, verifies, video, void, war, way, weight, whats\n",
      " - *hdb:* ankle, bit, bo, bookout, comfortable, completion, compulsory, ext, frequency, happen, hdb, hours, impact, leadership, mth, opinions, pants, requirements, resumption, round, search, superiors, supply, tt, use, valid, worst, yea\n",
      " - *indication:* indication, kinds, scheme, sign, tag, tend\n",
      " - *role:* compare, role\n",
      " - *implement:* implement\n",
      " - *bleed:* activities, bleed, conduct, endorse, fallout, folks, intake, know, lack, planning, prevent, reliable, safe, stuck, understand\n",
      " - *drag:* drag\n",
      " - *guaranteed:* account, authority, background, btw, guaranteed, sorry, trial, updates, vibrate\n",
      " - *gradient:* gradient\n",
      " - *ideas:* ideas\n",
      " - *oots:* buddy, counted, oots, push\n",
      " - *feeling:* feeling\n",
      " - *stars:* assist, entitlement, fy, greent, mob, reasons, stars, step, tbh\n",
      " - *shoes:* backside, boys, cmi, computer, experiences, icts, shelter, shoes, signs, wasted\n",
      " - *prep:* catch, prep\n",
      " - *confidential:* burpees, combat, confidential, course, deadline, feb, february, hate, paper, sop, suitable, tmr, unsure\n",
      " - *speculation:* convince, moment, nsf, opportunities, options, speculation, weather\n",
      " - *semesters:* believe, bookings, mental, semesters\n",
      " - *chiongsua:* chiongsua\n",
      " - *overstress:* left, mind, overstress\n",
      " - *knock:* enlistee, fight, hiit, knock, leave, pay, ps\n",
      " - *script:* banner, family, matter, ok, script\n",
      " - *commences:* claim, commences, soldiers\n",
      " - *cancellations:* alot, cancellations, charges, commando, decision, rts, rumours, tips\n",
      " - *food:* brothers, feed, food, income, trainers\n",
      " - *hit:* dependent, hit, opportunity, pros, servicemen, stance, tougher\n",
      " - *correction:* correction\n",
      " - *fees:* advisable, away, beat, cause, choose, deal, distance, earn, fees, fi, fiit, fk, fug, handle, info, jan, june, lk, lunch, majority, manpower, manual, office, okay, payable, permission, photo, platform, posts, qns, ranger, recommend, records, regulars, reports, respond, slippers, source, stations, suay, teach, thank, tired, turn, unreasonable, verify, words\n",
      " - *streamline:* medals, pushups, streamline\n",
      " - *forms:* forms\n",
      " - *generate:* applicable, attitude, cancel, chance, cleared, close, confused, division, drive, generate, gold, help, interest, length, luck, malays, moi, mths, noted, obligation, offender, ops, range, reach, reopens, rifle, right, salary, screening, singapore, squeeze, suggestion, transport, unfair, vocations, walk, warm, yellow\n",
      " - *prob:* complete, parents, prob\n",
      " - *keeps:* keeps\n",
      " - *passes:* cd, colour, difference, follow, gpmg, medical, nsfs, passes, pray, sar, sets, site, tracks, wanted\n"
     ]
    }
   ],
   "source": [
    "word_array = np.array(words)\n",
    "print(\"Total no. of clusters: \", len(affprop_glove.cluster_centers_indices_))\n",
    "for cluster_id in np.unique(affprop_glove.labels_):\n",
    "    exemplar = word_array[affprop_glove.cluster_centers_indices_[cluster_id]]\n",
    "    cluster = np.unique(word_array[np.nonzero(affprop_glove.labels_ == cluster_id)])\n",
    "    cluster_str = \", \".join(cluster)\n",
    "    print(\" - *%s:* %s\" % (exemplar, cluster_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette score: -0.01159183009910761\n",
      "Calinski Harabasz: 4.019040661069761\n",
      "Davies Bouldin: 2.3162252707756577\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Silhouette score:\", metrics.silhouette_score(X_glove, affprop_glove.labels_, metric='euclidean'))\n",
    "print(\"Calinski Harabasz:\", metrics.calinski_harabasz_score(X_glove, affprop_glove.labels_))\n",
    "print(\"Davies Bouldin:\", metrics.davies_bouldin_score(X_glove, affprop_glove.labels_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
